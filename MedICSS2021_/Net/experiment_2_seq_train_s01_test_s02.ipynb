{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebdb838",
   "metadata": {},
   "source": [
    "<h1>Experiment 2</h1>\n",
    "<h3>Test the robustness of each network to the undersampled data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from FormatData import generate_data, parser as data_parser\n",
    "from Training import train_network\n",
    "from utils.model import parser as model_parser\n",
    "from Testing import test_model\n",
    "from utils.nii_utils import mask_nii_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subject = 's01_still'\n",
    "# test_subjects = ['s02_still', 's03_still_reg', 's04_still_reg']\n",
    "test_subjects = ['s02_still']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    \"\"\"\n",
    "    a class generate parser for cmd line args\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e78ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "packages that handle graphs\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm, LinearSegmentedColormap\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from utils import calc_ssim\n",
    "%matplotlib inline\n",
    "def plot_loss(cmd):\n",
    "    \"\"\"\n",
    "    A function that used to plot the loss curve for the trained network.\n",
    "    Args:\n",
    "        cmd: String, the command line in the terminal\n",
    "    \"\"\"\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    history = train_network(args)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def show_slices(slices, grayscale=True):\n",
    "    \"\"\"\n",
    "    Function to display the slices\n",
    "\n",
    "    Args:\n",
    "        slices (list): a list of 2d ndarray that contains the data to be displayed\n",
    "        grayscale (bool, optional): True, if diplay grayscale img. Defaults to True.\n",
    "    \"\"\"    \n",
    "    fig, axes = plt.subplots(1, len(slices), figsize=(10,10))\n",
    "    cax = fig.add_axes([0, 0, .3, .3])\n",
    "    for i, slice in enumerate(slices):\n",
    "        # use grayscale for displaying ref and pred imgs:\n",
    "        if grayscale:\n",
    "            cmap = plt.get_cmap('gray')\n",
    "            cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "            cmap = LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "            bounds = np.arange(0, 1.0, .01)\n",
    "            idx = np.searchsorted(bounds, 0)\n",
    "            bounds = np.insert(bounds, idx, 0)\n",
    "            norm = BoundaryNorm(bounds, cmap.N)\n",
    "            im = axes[i].imshow(slice.T, cmap=cmap, origin=\"lower\", interpolation='none', norm=norm)\n",
    "        else:\n",
    "            # define the colormap\n",
    "            cmap = plt.get_cmap('bwr')\n",
    "            # extract all colors from the .jet map\n",
    "            cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "            # create the new map\n",
    "            cmap = LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "            # define the bins and normalize and forcing 0 to be part of the colorbar\n",
    "            # define the min and max to be -1 and +1 respectively\n",
    "            bounds = np.arange(-0.5, 0.5, .01)\n",
    "            idx = np.searchsorted(bounds, 0)\n",
    "            bounds = np.insert(bounds, idx, 0)\n",
    "            norm = BoundaryNorm(bounds, cmap.N)\n",
    "            im = axes[i].imshow(slice.T, cmap=cmap, origin=\"lower\", interpolation='none', norm=norm)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "def scale(img):\n",
    "    # for i in range(img.shape[0]):\n",
    "    #     for j in range(img.shape[1]):\n",
    "    #         img[i][j] = ((img[i][j]+1)/2)*255\n",
    "    return img\n",
    "\n",
    "def compare_simi(pred, ref):\n",
    "    return calc_ssim(pred, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3af471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise0(ref):\n",
    "    \"\"\"\n",
    "    Function to visualise the ref imgs\n",
    "\n",
    "    Args:\n",
    "        ref (ndarray): the reference data\n",
    "    \"\"\"\n",
    "    # visualise the ref imgs\n",
    "    ref0 = ref[26, :, :]\n",
    "    ref1 = ref[:, 30, :]\n",
    "    ref2 = ref[:, :, 16]\n",
    "    show_slices([ref0, ref1, ref2])\n",
    "    plt.suptitle(\"Center slices for reference image\")\n",
    "\n",
    "\n",
    "def visualise1(ref_ndi, retained_vol, subject, model, layer, affine):\n",
    "    \"\"\"\n",
    "    Function to visualise the NDI imgs and store the difference map\n",
    "\n",
    "    Args:\n",
    "        ref_ndi (ndarray): the reference NDI data\n",
    "        subject (string): the subject that is examined\n",
    "        model (string): the model used\n",
    "        layer (int): the number of layers for the network\n",
    "        retained_vol (int): the number of volumes used\n",
    "    \"\"\"\n",
    "    patch = 3\n",
    "    if model == 'fc1d':\n",
    "        patch = 1\n",
    "\n",
    "    print(patch)\n",
    "    print(model)\n",
    "    # visualise the ref imgs\n",
    "    refNDI0 = ref_ndi[26, :, :]\n",
    "    refNDI1 = ref_ndi[:, 30, :]\n",
    "    refNDI2 = ref_ndi[:, :, 16]\n",
    "\n",
    "    # visualise the pred imgs produced at varied input size\n",
    "    ndi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDIsynthetic.nii'\n",
    "    ndi_img = nib.load(ndi_path)\n",
    "    ndi_data = ndi_img.get_fdata()\n",
    "\n",
    "    ndi0 = ndi_data[26, :, :]\n",
    "    ndi1 = ndi_data[:, 30, :]\n",
    "    ndi2 = ndi_data[:, :, 16]\n",
    "    show_slices([ndi0, ndi1, ndi2])\n",
    "    plt.suptitle('Center slices for NDI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, ndidiff) = compare_ssim(ndi_data, ref_ndi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for ndi is: ' + str(score))\n",
    "\n",
    "    # plot the difference map between the imgs by the lib\n",
    "    ndidiff0 = scale(refNDI0 - ndi0)\n",
    "    ndidiff1 = scale(refNDI1 - ndi1)\n",
    "    ndidiff2 = scale(refNDI2 - ndi2)\n",
    "    show_slices([ndidiff0, ndidiff1, ndidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map NDI\")\n",
    "\n",
    "    diff_img_np = ref_ndi - ndi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDI_difference_synthetic.nii')\n",
    "\n",
    "def visualise2(ref_odi, retained_vol, subject, model, layer, affine):\n",
    "    \"\"\"\n",
    "    Function to visualise the ODI imgs and difference maps\n",
    "\n",
    "    Args:\n",
    "        ref_odi (ndarray): the reference ODI data\n",
    "        retained_vol (int): the number of volumes retained after rejection\n",
    "        subject (string): the subject that is examined\n",
    "        model (string): the model used\n",
    "        layer (int): the number of layers for the network\n",
    "    \"\"\"\n",
    "    patch = 3\n",
    "    if model == 'fc1d':\n",
    "        patch = 1\n",
    "\n",
    "    print(patch)\n",
    "    print(model)\n",
    "    # visualise the ref imgs\n",
    "    refODI0 = ref_odi[26, :, :]\n",
    "    refODI1 = ref_odi[:, 30, :]\n",
    "    refODI2 = ref_odi[:, :, 16]\n",
    "\n",
    "    # visualise the pred imgs produced at varied input size\n",
    "    odi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODIsynthetic.nii'\n",
    "    odi_img = nib.load(odi_path)\n",
    "    odi_data = odi_img.get_fdata()\n",
    "\n",
    "    odi0 = odi_data[26, :, :]\n",
    "    odi1 = odi_data[:, 30, :]\n",
    "    odi2 = odi_data[:, :, 16]\n",
    "    show_slices([odi0, odi1, odi2])\n",
    "    plt.suptitle('Center slices for ODI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, odidiff) = compare_ssim(odi_data, ref_odi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for odi is: ' + str(score))\n",
    "\n",
    "    odidiff0 = scale(refODI0 - odi0)\n",
    "    odidiff1 = scale(refODI1 - odi1)\n",
    "    odidiff2 = scale(refODI2 - odi2)\n",
    "    show_slices([odidiff0, odidiff1, odidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map ODI\")\n",
    "\n",
    "    diff_img_np = ref_odi - odi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODI_difference_synthetic.nii')\n",
    "\n",
    "def visualise3(ref_fwf, retained_vol, subject, model, layer, affine):\n",
    "    \"\"\"\n",
    "    Function to visualise the fwf imgs and difference maps\n",
    "\n",
    "    Args:\n",
    "        ref_fwf (ndarray): the reference FWF data\n",
    "        retained_vol (int): the number of volumes retained after rejection\n",
    "        subject (string): the subject that is examined\n",
    "        model (string): the model used\n",
    "        layer (int): the number of layers for the network\n",
    "    \"\"\"\n",
    "    patch = 3\n",
    "    if model == 'fc1d':\n",
    "        patch = 1\n",
    "\n",
    "    print(patch)\n",
    "    print(model)\n",
    "    # visualise the ref imgs\n",
    "    refFWF0 = ref_fwf[26, :, :]\n",
    "    refFWF1 = ref_fwf[:, 30, :]\n",
    "    refFWF2 = ref_fwf[:, :, 16]\n",
    "\n",
    "    # visualise the pred imgs produced at varied input size\n",
    "    fwf_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWFsynthetic.nii'\n",
    "    fwf_img = nib.load(fwf_path)\n",
    "    fwf_data = fwf_img.get_fdata()\n",
    "\n",
    "    fwf0 = fwf_data[26, :, :]\n",
    "    fwf1 = fwf_data[:, 30, :]\n",
    "    fwf2 = fwf_data[:, :, 16]\n",
    "    show_slices([fwf0, fwf1, fwf2])\n",
    "    plt.suptitle('Center slices for FWF predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, fwfdiff) = compare_ssim(fwf_data, ref_fwf, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for fwf is: ' + str(score))\n",
    "\n",
    "    # plot the difference map between the imgs by the lib\n",
    "    fwfdiff0 = scale(refFWF0 - fwf0)\n",
    "    fwfdiff1 = scale(refFWF1 - fwf1)\n",
    "    fwfdiff2 = scale(refFWF2 - fwf2)\n",
    "    show_slices([fwfdiff0, fwfdiff1, fwfdiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map FWF\")\n",
    "\n",
    "    diff_img_np = ref_fwf - fwf_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWF_difference_synthetic.nii')\n",
    "\n",
    "def visualise4(ref_ndi, ref_odi, ref_fwf, retained_vol, subject, model, layer, affine1, affine2, affine3):\n",
    "    \"\"\"\n",
    "    Function to visualise the imgs and difference maps\n",
    "\n",
    "    Args:\n",
    "        ref_ndi (ndarray): the reference NDI data\n",
    "        ref_odi (ndarray): the reference ODI data\n",
    "        ref_fwf (ndarray): the reference FWF data\n",
    "        retained_vol (int): the number of volumes retained after rejection\n",
    "        subject (string): the subject that is examined\n",
    "        model (string): the model used\n",
    "        layer (int): the number of layers for the network\n",
    "    \"\"\"\n",
    "    patch = 3\n",
    "    if model == 'fc1d':\n",
    "        patch = 1\n",
    "\n",
    "    print(patch)\n",
    "    print(model)\n",
    "    # visualise the ref imgs\n",
    "    refNDI0 = ref_ndi[26, :, :]\n",
    "    refNDI1 = ref_ndi[:, 30, :]\n",
    "    refNDI2 = ref_ndi[:, :, 16]\n",
    "\n",
    "    refODI0 = ref_odi[26, :, :]\n",
    "    refODI1 = ref_odi[:, 30, :]\n",
    "    refODI2 = ref_odi[:, :, 16]\n",
    "\n",
    "    refFWF0 = ref_fwf[26, :, :]\n",
    "    refFWF1 = ref_fwf[:, 30, :]\n",
    "    refFWF2 = ref_fwf[:, :, 16]\n",
    "\n",
    "    # visualise the pred imgs produced at varied input size\n",
    "    ndi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDIsynthetic.nii'\n",
    "    odi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODIsynthetic.nii'\n",
    "    fwf_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWFsynthetic.nii'\n",
    "    ndi_img = nib.load(ndi_path)\n",
    "    ndi_data = ndi_img.get_fdata()\n",
    "    odi_img = nib.load(odi_path)\n",
    "    odi_data = odi_img.get_fdata()\n",
    "    fwf_img = nib.load(fwf_path)\n",
    "    fwf_data = fwf_img.get_fdata()\n",
    "\n",
    "    ndi0 = ndi_data[26, :, :]\n",
    "    ndi1 = ndi_data[:, 30, :]\n",
    "    ndi2 = ndi_data[:, :, 16]\n",
    "    show_slices([ndi0, ndi1, ndi2])\n",
    "    plt.suptitle('Center slices for NDI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, ndidiff) = compare_ssim(ndi_data, ref_ndi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for ndi is: ' + str(score))\n",
    "\n",
    "    odi0 = odi_data[26, :, :]\n",
    "    odi1 = odi_data[:, 30, :]\n",
    "    odi2 = odi_data[:, :, 16]\n",
    "    show_slices([odi0, odi1, odi2])\n",
    "    plt.suptitle('Center slices for ODI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, odidiff) = compare_ssim(odi_data, ref_odi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for odi is: ' + str(score))\n",
    "\n",
    "    fwf0 = fwf_data[26, :, :]\n",
    "    fwf1 = fwf_data[:, 30, :]\n",
    "    fwf2 = fwf_data[:, :, 16]\n",
    "    show_slices([fwf0, fwf1, fwf2])\n",
    "    plt.suptitle('Center slices for FWF predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, fwfdiff) = compare_ssim(fwf_data, ref_fwf, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for fwf is: ' + str(score))\n",
    "\n",
    "    # plot the difference map between the imgs by the lib\n",
    "    ndidiff0 = scale(refNDI0 - ndi0)\n",
    "    ndidiff1 = scale(refNDI1 - ndi1)\n",
    "    ndidiff2 = scale(refNDI2 - ndi2)\n",
    "    show_slices([ndidiff0, ndidiff1, ndidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map NDI\")\n",
    "\n",
    "    diff_img_np = ref_ndi - ndi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine1)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDI_difference_synthetic.nii')\n",
    "\n",
    "    odidiff0 = scale(refODI0 - odi0)\n",
    "    odidiff1 = scale(refODI1 - odi1)\n",
    "    odidiff2 = scale(refODI2 - odi2)\n",
    "    show_slices([odidiff0, odidiff1, odidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map ODI\")\n",
    "\n",
    "    diff_img_np = ref_odi - odi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine2)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODI_difference_synthetic.nii')\n",
    "\n",
    "    fwfdiff0 = scale(refFWF0 - fwf0)\n",
    "    fwfdiff1 = scale(refFWF1 - fwf1)\n",
    "    fwfdiff2 = scale(refFWF2 - fwf2)\n",
    "    show_slices([fwfdiff0, fwfdiff1, fwfdiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map FWF\")\n",
    "\n",
    "    diff_img_np = ref_fwf - fwf_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine3)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWF_difference_synthetic.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21bb98d",
   "metadata": {},
   "source": [
    "___\n",
    "<h3>Data Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c433e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion-free subject path\n",
    "s01_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/'\n",
    "s02_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/'\n",
    "s03_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/'\n",
    "s04_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/'\n",
    "# motion-free target labels\n",
    "s01_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_NDI.nii'\n",
    "s02_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_NDI.nii'\n",
    "s03_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/s03_still_reg_NDI.nii'\n",
    "s04_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/s04_still_reg_NDI.nii'\n",
    "\n",
    "s01_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_ODI.nii'\n",
    "s02_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_ODI.nii'\n",
    "s03_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/s03_still_reg_ODI.nii'\n",
    "s04_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/s04_still_reg_ODI.nii'\n",
    "\n",
    "s01_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_FWF.nii'\n",
    "s02_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_FWF.nii'\n",
    "s03_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/s03_still_reg_FWF.nii'\n",
    "s04_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/s04_still_reg_FWF.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask(subpath, fwfpath, threshold=0.99):\n",
    "    \"\"\"\n",
    "    By looking at the imgs generated, we have found out there are some regions that should not be included. Since they have values higher than 1.0\n",
    "    And we have found out voxels have NDI and ODI values, while that voxel has GROUND TRUTH FWF 1.0\n",
    "    This should indicate that that voxel should not even be included in the training\n",
    "    Therefore we want to filter the each subject's mask first, by using their corresponding GROUND TRUTH FWF\n",
    "\n",
    "    Args:\n",
    "        subpath (string): the path of the subject folder\n",
    "        fwfpath (string): the path of the corresponding fwf file\n",
    "        threshold (float): the thresholds to be used to filter of the mask,\n",
    "                           a stringnent threshold would be 0.9, the least stringnent threshold is 1.0\n",
    "                           by default, it is set to 0.99\n",
    "    \"\"\"\n",
    "    # fetch the mask data\n",
    "    img_mask = nib.load(subpath+'mask-e.nii')\n",
    "    original_mask = img_mask.get_fdata()\n",
    "    original_affine = img_mask.affine\n",
    "    shape = original_mask.shape # retain the shape of the mask\n",
    "    origin_nonzeros = np.count_nonzero(original_mask)\n",
    "    print('original mask has: ' + str(origin_nonzeros) + ' of nonzero voxels')\n",
    "    # fetch the FWF data\n",
    "    fwf = nib.load(fwfpath).get_fdata()\n",
    "    # filter\n",
    "    mask = original_mask.flatten() # this makes a copy of the orginal mask\n",
    "    fwf = fwf.reshape(mask.shape[0]) # reshape fwf to the corresponding shape\n",
    "    for i in range(len(mask)):\n",
    "        # if fwf has high value, means there is no tissue\n",
    "        # therefore, the voxel should be excluded\n",
    "        if fwf[i] >= threshold:\n",
    "            mask[i] = 0.0\n",
    "    # reshape mask back\n",
    "    mask = mask.reshape(shape)\n",
    "    filter_nonzeros = np.count_nonzero(mask)\n",
    "    print('filtered mask has: ' +str(filter_nonzeros) + ' of nonzero voxels')\n",
    "    # save the mask\n",
    "    filter_img = nib.Nifti1Image(mask, original_affine)\n",
    "    nib.save(filter_img, subpath+'filtered_mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1778b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above code to filter each subject's mask. Store as filtered_mask.nii in each subject folder\n",
    "filter_mask(s01_path, s01_FWF_path)\n",
    "filter_mask(s02_path, s02_FWF_path)\n",
    "filter_mask(s03_path, s04_FWF_path)\n",
    "filter_mask(s04_path, s03_FWF_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd11d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered mask path for each subject\n",
    "s01_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/filtered_mask.nii'\n",
    "s02_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/filtered_mask.nii'\n",
    "s03_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/filtered_mask.nii'\n",
    "s04_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/filtered_mask.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6068e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate base datasets for each subject\n",
    "\"\"\"\n",
    "ltype = ['A']\n",
    "for l in ltype:\n",
    "    print('Generating basedataset for label: ' + l)\n",
    "    cmd = '--base --label_type ' + l + ' --subjects s01_still s02_still'\n",
    "    args = data_parser().parse_args(cmd.split())\n",
    "    generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b468fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset for ANN.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still s02_still --fc1d --label_type A\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d286b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset for 2D CNN\n",
    "cmd = \"--subjects s01_still s02_still --conv2d --label_type A\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset for 3D CNN\n",
    "cmd = \"--subjects s01_still s02_still --conv3d --label_type A\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using nib to fetch the ground truth img\n",
    "\"\"\"\n",
    "#load the truth data for subject 1\n",
    "s01_NDI_img = nib.load(s01_NDI_path)\n",
    "s01_ODI_img = nib.load(s01_ODI_path)\n",
    "s01_FWF_img = nib.load(s01_FWF_path)\n",
    "s01_NDI_affine = s01_NDI_img.affine\n",
    "s01_ODI_affine = s01_ODI_img.affine\n",
    "s01_FWF_affine = s01_FWF_img.affine\n",
    "s01_NDI_img_data = s01_NDI_img.get_fdata()\n",
    "s01_ODI_img_data = s01_ODI_img.get_fdata()\n",
    "s01_FWF_img_data = s01_FWF_img.get_fdata()\n",
    "#load the truth data for subject 2\n",
    "s02_NDI_img = nib.load(s02_NDI_path)\n",
    "s02_ODI_img = nib.load(s02_ODI_path)\n",
    "s02_FWF_img = nib.load(s02_FWF_path)\n",
    "s02_NDI_affine = s02_NDI_img.affine\n",
    "s02_ODI_affine = s02_ODI_img.affine\n",
    "s02_FWF_affine = s02_FWF_img.affine\n",
    "s02_NDI_img_data = s02_NDI_img.get_fdata()\n",
    "s02_ODI_img_data = s02_ODI_img.get_fdata()\n",
    "s02_FWF_img_data = s02_FWF_img.get_fdata()\n",
    "# load the truth data for subject 3\n",
    "s03_NDI_img = nib.load(s03_NDI_path)\n",
    "s03_ODI_img = nib.load(s03_ODI_path)\n",
    "s03_FWF_img = nib.load(s03_FWF_path)\n",
    "s03_NDI_affine = s03_NDI_img.affine\n",
    "s03_ODI_affine = s03_ODI_img.affine\n",
    "s03_FWF_affine = s03_FWF_img.affine\n",
    "s03_NDI_img_data = s03_NDI_img.get_fdata()\n",
    "s03_ODI_img_data = s03_ODI_img.get_fdata()\n",
    "s03_FWF_img_data = s03_FWF_img.get_fdata()\n",
    "# load the truth data for subject 4\n",
    "s04_NDI_img = nib.load(s04_NDI_path)\n",
    "s04_ODI_img = nib.load(s04_ODI_path)\n",
    "s04_FWF_img = nib.load(s04_FWF_path)\n",
    "s04_NDI_affine = s04_NDI_img.affine\n",
    "s04_ODI_affine = s04_ODI_img.affine\n",
    "s04_FWF_affine = s04_FWF_img.affine\n",
    "s04_NDI_img_data = s04_NDI_img.get_fdata()\n",
    "s04_ODI_img_data = s04_ODI_img.get_fdata()\n",
    "s04_FWF_img_data = s04_FWF_img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee625bd",
   "metadata": {},
   "source": [
    "<h4>Test the performace of each network to generate each parameter with varied number of DWI as input size</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c6a8b",
   "metadata": {},
   "source": [
    "Each network (ANN, 2D CNN and 3D CNN) should be implemented with 5 hidden layers. The choice is suggested from the obtained results from the previous experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79161332",
   "metadata": {},
   "source": [
    "DWI = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1972af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c82f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6315b1",
   "metadata": {},
   "source": [
    "DWI = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2226ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f36f5",
   "metadata": {},
   "source": [
    "DWI = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11456be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5030fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df27997",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52d83d",
   "metadata": {},
   "source": [
    "DWI = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e43fe",
   "metadata": {},
   "source": [
    "DWI = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd62b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877748c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff5651",
   "metadata": {},
   "source": [
    "DWI = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf92af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b161dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3691a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43298018",
   "metadata": {},
   "source": [
    "DWI = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d321e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1490862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2213b504",
   "metadata": {},
   "source": [
    "DWI = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef858ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3203aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dacf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c104b0b2",
   "metadata": {},
   "source": [
    "DWI = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9abd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9848767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D 4\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ff0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b267dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc77c2d",
   "metadata": {},
   "source": [
    "DWI = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99348de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s01_NDI_img_data)\n",
    "visualise0(s01_ODI_img_data)\n",
    "visualise0(s01_FWF_img_data)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'fc1d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'conv2d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'conv3d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee46c0ef",
   "metadata": {},
   "source": [
    "DWI = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03345b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s01_NDI_img_data)\n",
    "visualise0(s01_ODI_img_data)\n",
    "visualise0(s01_FWF_img_data)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'fc1d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'conv2d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'conv3d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f383cb0",
   "metadata": {},
   "source": [
    "DWI = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e26b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c606d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s01_NDI_img_data)\n",
    "visualise0(s01_ODI_img_data)\n",
    "visualise0(s01_FWF_img_data)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'fc1d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'conv2d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'conv3d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ef2c9",
   "metadata": {},
   "source": [
    "DWI = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2afced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f71809",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s01_NDI_img_data)\n",
    "visualise0(s01_ODI_img_data)\n",
    "visualise0(s01_FWF_img_data)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'fc1d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'conv2d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)\n",
    "visualise4(s01_NDI_img_data, s01_ODI_img_data, s01_FWF_img_data, dwi, 's01_still', 'conv3d', 4, s01_NDI_affine, s01_ODI_affine, s01_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75982a63",
   "metadata": {},
   "source": [
    "DWI = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf123c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4c57f",
   "metadata": {},
   "source": [
    "DWI = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d62fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b48a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df165a4",
   "metadata": {},
   "source": [
    "DWI = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165ba23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec49e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24168e35",
   "metadata": {},
   "source": [
    "DWI = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fedc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55aec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b946866",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b8e2e",
   "metadata": {},
   "source": [
    "DWI = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed488d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d234a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0298240",
   "metadata": {},
   "source": [
    "DWI = 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80779601",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aae040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e300d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9bd27b",
   "metadata": {},
   "source": [
    "DWI = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a515ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd70c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d1a08",
   "metadata": {},
   "source": [
    "DWI = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model fc1d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc89c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv2d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN\n",
    "train_cmd = \"--train_subjects \"+train_subject+\" --model conv3d --layer 4 --train --label_type A --DWI \" + str(dwi)\n",
    "plot_loss(train_cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer 4 --label_type A --DWI ' + str(dwi)\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise0(s02_NDI_img_data)\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'fc1d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv2d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)\n",
    "visualise4(s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data, dwi, 's02_still', 'conv3d', 4, s02_NDI_affine, s02_ODI_affine, s02_FWF_affine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
