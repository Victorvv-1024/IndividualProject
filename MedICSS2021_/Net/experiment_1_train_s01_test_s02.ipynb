{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebdb838",
   "metadata": {},
   "source": [
    "<h1>Experiment 1</h1>\n",
    "<h3>Test the number of layers acquired to output promising NODDI measure for three networks</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from FormatData import generate_data, parser as data_parser\n",
    "from Training import train_network\n",
    "from utils.model import parser as model_parser\n",
    "from Testing import test_model\n",
    "from utils.nii_utils import mask_nii_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8495c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subject = 's01_still'\n",
    "# test_subjects = ['s02_still', 's03_still_reg', 's04_still_reg']\n",
    "test_subjects = ['s02_still']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    \"\"\"\n",
    "    a class generate parser for cmd line args\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e78ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "packages that handle graphs\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm, LinearSegmentedColormap\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from utils import calc_ssim\n",
    "%matplotlib inline\n",
    "def plot_loss(cmd):\n",
    "    \"\"\"\n",
    "    A function that used to plot the loss curve for the trained network.\n",
    "    Args:\n",
    "        cmd: String, the command line in the terminal\n",
    "    \"\"\"\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    history = train_network(args)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def show_slices(slices, grayscale=True):\n",
    "    \"\"\"\n",
    "    Function to display the slices\n",
    "\n",
    "    Args:\n",
    "        slices (list): a list of 2d ndarray that contains the data to be displayed\n",
    "        grayscale (bool, optional): True, if diplay grayscale img. Defaults to True.\n",
    "    \"\"\"    \n",
    "    fig, axes = plt.subplots(1, len(slices), figsize=(10,10))\n",
    "    cax = fig.add_axes([0, 0, .3, .3])\n",
    "    for i, slice in enumerate(slices):\n",
    "        # use grayscale for displaying ref and pred imgs:\n",
    "        if grayscale:\n",
    "            cmap = plt.get_cmap('gray')\n",
    "            cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "            cmap = LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "            bounds = np.arange(0, 1.0, .01)\n",
    "            idx = np.searchsorted(bounds, 0)\n",
    "            bounds = np.insert(bounds, idx, 0)\n",
    "            norm = BoundaryNorm(bounds, cmap.N)\n",
    "            im = axes[i].imshow(slice.T, cmap=cmap, origin=\"lower\", interpolation='none', norm=norm)\n",
    "        else:\n",
    "            # define the colormap\n",
    "            cmap = plt.get_cmap('bwr')\n",
    "            # extract all colors from the .jet map\n",
    "            cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "            # create the new map\n",
    "            cmap = LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "            # define the bins and normalize and forcing 0 to be part of the colorbar\n",
    "            # define the min and max to be -1 and +1 respectively\n",
    "            bounds = np.arange(-0.5, 0.5, .01)\n",
    "            idx = np.searchsorted(bounds, 0)\n",
    "            bounds = np.insert(bounds, idx, 0)\n",
    "            norm = BoundaryNorm(bounds, cmap.N)\n",
    "            im = axes[i].imshow(slice.T, cmap=cmap, origin=\"lower\", interpolation='none', norm=norm)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "def scale(img):\n",
    "    # for i in range(img.shape[0]):\n",
    "    #     for j in range(img.shape[1]):\n",
    "    #         img[i][j] = ((img[i][j]+1)/2)*255\n",
    "    return img\n",
    "\n",
    "def compare_simi(pred, ref):\n",
    "    return calc_ssim(pred, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3af471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise0(ref):\n",
    "    \"\"\"\n",
    "    Function to visualise the ref imgs\n",
    "\n",
    "    Args:\n",
    "        ref (ndarray): the reference data\n",
    "    \"\"\"\n",
    "    # visualise the ref imgs\n",
    "    ref0 = ref[26, :, :]\n",
    "    ref1 = ref[:, 30, :]\n",
    "    ref2 = ref[:, :, 16]\n",
    "    show_slices([ref0, ref1, ref2])\n",
    "    plt.suptitle(\"Center slices for reference image\")\n",
    "\n",
    "\n",
    "def visualise1(ref_ndi, retained_vol, subject, model, layer, affine):\n",
    "    \"\"\"\n",
    "    Function to visualise the NDI imgs and store the difference map\n",
    "\n",
    "    Args:\n",
    "        ref_ndi (ndarray): the reference NDI data\n",
    "        subject (string): the subject that is examined\n",
    "        model (string): the model used\n",
    "        layer (int): the number of layers for the network\n",
    "        retained_vol (int): the number of volumes used\n",
    "    \"\"\"\n",
    "    patch = 3\n",
    "    if model == 'fc1d':\n",
    "        patch = 1\n",
    "\n",
    "    print(patch)\n",
    "    print(model)\n",
    "    # visualise the ref imgs\n",
    "    refNDI0 = ref_ndi[26, :, :]\n",
    "    refNDI1 = ref_ndi[:, 30, :]\n",
    "    refNDI2 = ref_ndi[:, :, 16]\n",
    "\n",
    "    # visualise the pred imgs produced at varied input size\n",
    "    ndi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDI.nii'\n",
    "    ndi_img = nib.load(ndi_path)\n",
    "    ndi_data = ndi_img.get_fdata()\n",
    "\n",
    "    ndi0 = ndi_data[26, :, :]\n",
    "    ndi1 = ndi_data[:, 30, :]\n",
    "    ndi2 = ndi_data[:, :, 16]\n",
    "    show_slices([ndi0, ndi1, ndi2])\n",
    "    plt.suptitle('Center slices for NDI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, ndidiff) = compare_ssim(ndi_data, ref_ndi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for ndi is: ' + str(score))\n",
    "\n",
    "    # plot the difference map between the imgs by the lib\n",
    "    ndidiff0 = scale(refNDI0 - ndi0)\n",
    "    ndidiff1 = scale(refNDI1 - ndi1)\n",
    "    ndidiff2 = scale(refNDI2 - ndi2)\n",
    "    show_slices([ndidiff0, ndidiff1, ndidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map NDI\")\n",
    "\n",
    "    diff_img_np = ref_ndi - ndi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDI_difference.nii')\n",
    "\n",
    "def visualise2(ref_odi, retained_vol, subject, model, layer, affine):\n",
    "    \"\"\"\n",
    "    Function to visualise the ODI imgs and difference maps\n",
    "\n",
    "    Args:\n",
    "        ref_odi (ndarray): the reference ODI data\n",
    "        retained_vol (int): the number of volumes retained after rejection\n",
    "        subject (string): the subject that is examined\n",
    "        model (string): the model used\n",
    "        layer (int): the number of layers for the network\n",
    "    \"\"\"\n",
    "    patch = 3\n",
    "    if model == 'fc1d':\n",
    "        patch = 1\n",
    "\n",
    "    print(patch)\n",
    "    print(model)\n",
    "    # visualise the ref imgs\n",
    "    refODI0 = ref_odi[26, :, :]\n",
    "    refODI1 = ref_odi[:, 30, :]\n",
    "    refODI2 = ref_odi[:, :, 16]\n",
    "\n",
    "    # visualise the pred imgs produced at varied input size\n",
    "    odi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODI.nii'\n",
    "    odi_img = nib.load(odi_path)\n",
    "    odi_data = odi_img.get_fdata()\n",
    "\n",
    "    odi0 = odi_data[26, :, :]\n",
    "    odi1 = odi_data[:, 30, :]\n",
    "    odi2 = odi_data[:, :, 16]\n",
    "    show_slices([odi0, odi1, odi2])\n",
    "    plt.suptitle('Center slices for ODI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, odidiff) = compare_ssim(odi_data, ref_odi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for odi is: ' + str(score))\n",
    "\n",
    "    odidiff0 = scale(refODI0 - odi0)\n",
    "    odidiff1 = scale(refODI1 - odi1)\n",
    "    odidiff2 = scale(refODI2 - odi2)\n",
    "    show_slices([odidiff0, odidiff1, odidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map ODI\")\n",
    "\n",
    "    diff_img_np = ref_odi - odi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODI_difference.nii')\n",
    "\n",
    "def visualise3(ref_fwf, retained_vol, subject, model, layer, affine):\n",
    "    \"\"\"\n",
    "    Function to visualise the fwf imgs and difference maps\n",
    "\n",
    "    Args:\n",
    "        ref_fwf (ndarray): the reference FWF data\n",
    "        retained_vol (int): the number of volumes retained after rejection\n",
    "        subject (string): the subject that is examined\n",
    "        model (string): the model used\n",
    "        layer (int): the number of layers for the network\n",
    "    \"\"\"\n",
    "    patch = 3\n",
    "    if model == 'fc1d':\n",
    "        patch = 1\n",
    "\n",
    "    print(patch)\n",
    "    print(model)\n",
    "    # visualise the ref imgs\n",
    "    refFWF0 = ref_fwf[26, :, :]\n",
    "    refFWF1 = ref_fwf[:, 30, :]\n",
    "    refFWF2 = ref_fwf[:, :, 16]\n",
    "\n",
    "    # visualise the pred imgs produced at varied input size\n",
    "    fwf_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWF.nii'\n",
    "    fwf_img = nib.load(fwf_path)\n",
    "    fwf_data = fwf_img.get_fdata()\n",
    "\n",
    "    fwf0 = fwf_data[26, :, :]\n",
    "    fwf1 = fwf_data[:, 30, :]\n",
    "    fwf2 = fwf_data[:, :, 16]\n",
    "    show_slices([fwf0, fwf1, fwf2])\n",
    "    plt.suptitle('Center slices for FWF predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, fwfdiff) = compare_ssim(fwf_data, ref_fwf, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for fwf is: ' + str(score))\n",
    "\n",
    "    # plot the difference map between the imgs by the lib\n",
    "    fwfdiff0 = scale(refFWF0 - fwf0)\n",
    "    fwfdiff1 = scale(refFWF1 - fwf1)\n",
    "    fwfdiff2 = scale(refFWF2 - fwf2)\n",
    "    show_slices([fwfdiff0, fwfdiff1, fwfdiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map FWF\")\n",
    "\n",
    "    diff_img_np = ref_fwf - fwf_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWF_difference.nii')\n",
    "\n",
    "def visualise4(ref_ndi, ref_odi, ref_fwf, retained_vol, subject, model, layer, affine1, affine2, affine3):\n",
    "    \"\"\"\n",
    "    Function to visualise the imgs and difference maps\n",
    "\n",
    "    Args:\n",
    "        ref_ndi (ndarray): the reference NDI data\n",
    "        ref_odi (ndarray): the reference ODI data\n",
    "        ref_fwf (ndarray): the reference FWF data\n",
    "        retained_vol (int): the number of volumes retained after rejection\n",
    "        subject (string): the subject that is examined\n",
    "        model (string): the model used\n",
    "        layer (int): the number of layers for the network\n",
    "    \"\"\"\n",
    "    patch = 3\n",
    "    if model == 'fc1d':\n",
    "        patch = 1\n",
    "\n",
    "    print(patch)\n",
    "    print(model)\n",
    "    # visualise the ref imgs\n",
    "    refNDI0 = ref_ndi[26, :, :]\n",
    "    refNDI1 = ref_ndi[:, 30, :]\n",
    "    refNDI2 = ref_ndi[:, :, 16]\n",
    "\n",
    "    refODI0 = ref_odi[26, :, :]\n",
    "    refODI1 = ref_odi[:, 30, :]\n",
    "    refODI2 = ref_odi[:, :, 16]\n",
    "\n",
    "    refFWF0 = ref_fwf[26, :, :]\n",
    "    refFWF1 = ref_fwf[:, 30, :]\n",
    "    refFWF2 = ref_fwf[:, :, 16]\n",
    "\n",
    "    # visualise the pred imgs produced at varied input size\n",
    "    ndi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDI.nii'\n",
    "    odi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODI.nii'\n",
    "    fwf_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWF.nii'\n",
    "    ndi_img = nib.load(ndi_path)\n",
    "    ndi_data = ndi_img.get_fdata()\n",
    "    odi_img = nib.load(odi_path)\n",
    "    odi_data = odi_img.get_fdata()\n",
    "    fwf_img = nib.load(fwf_path)\n",
    "    fwf_data = fwf_img.get_fdata()\n",
    "\n",
    "    ndi0 = ndi_data[26, :, :]\n",
    "    ndi1 = ndi_data[:, 30, :]\n",
    "    ndi2 = ndi_data[:, :, 16]\n",
    "    show_slices([ndi0, ndi1, ndi2])\n",
    "    plt.suptitle('Center slices for NDI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, ndidiff) = compare_ssim(ndi_data, ref_ndi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for ndi is: ' + str(score))\n",
    "\n",
    "    odi0 = odi_data[26, :, :]\n",
    "    odi1 = odi_data[:, 30, :]\n",
    "    odi2 = odi_data[:, :, 16]\n",
    "    show_slices([odi0, odi1, odi2])\n",
    "    plt.suptitle('Center slices for ODI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, odidiff) = compare_ssim(odi_data, ref_odi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for odi is: ' + str(score))\n",
    "\n",
    "    fwf0 = fwf_data[26, :, :]\n",
    "    fwf1 = fwf_data[:, 30, :]\n",
    "    fwf2 = fwf_data[:, :, 16]\n",
    "    show_slices([fwf0, fwf1, fwf2])\n",
    "    plt.suptitle('Center slices for FWF predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, fwfdiff) = compare_ssim(fwf_data, ref_fwf, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for fwf is: ' + str(score))\n",
    "\n",
    "    # plot the difference map between the imgs by the lib\n",
    "    ndidiff0 = scale(refNDI0 - ndi0)\n",
    "    ndidiff1 = scale(refNDI1 - ndi1)\n",
    "    ndidiff2 = scale(refNDI2 - ndi2)\n",
    "    show_slices([ndidiff0, ndidiff1, ndidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map NDI\")\n",
    "\n",
    "    diff_img_np = ref_ndi - ndi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine1)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDI_difference.nii')\n",
    "\n",
    "    odidiff0 = scale(refODI0 - odi0)\n",
    "    odidiff1 = scale(refODI1 - odi1)\n",
    "    odidiff2 = scale(refODI2 - odi2)\n",
    "    show_slices([odidiff0, odidiff1, odidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map ODI\")\n",
    "\n",
    "    diff_img_np = ref_odi - odi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine2)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODI_difference.nii')\n",
    "\n",
    "    fwfdiff0 = scale(refFWF0 - fwf0)\n",
    "    fwfdiff1 = scale(refFWF1 - fwf1)\n",
    "    fwfdiff2 = scale(refFWF2 - fwf2)\n",
    "    show_slices([fwfdiff0, fwfdiff1, fwfdiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map FWF\")\n",
    "\n",
    "    diff_img_np = ref_fwf - fwf_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine3)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWF_difference.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21bb98d",
   "metadata": {},
   "source": [
    "___\n",
    "<h3>Data Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c433e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion-free subject path\n",
    "s01_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/'\n",
    "s02_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/'\n",
    "s03_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/'\n",
    "s04_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/'\n",
    "# motion-free target labels\n",
    "s01_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_NDI.nii'\n",
    "s02_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_NDI.nii'\n",
    "s03_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/s03_still_reg_NDI.nii'\n",
    "s04_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/s04_still_reg_NDI.nii'\n",
    "\n",
    "s01_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_ODI.nii'\n",
    "s02_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_ODI.nii'\n",
    "s03_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/s03_still_reg_ODI.nii'\n",
    "s04_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/s04_still_reg_ODI.nii'\n",
    "\n",
    "s01_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_FWF.nii'\n",
    "s02_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_FWF.nii'\n",
    "s03_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/s03_still_reg_FWF.nii'\n",
    "s04_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/s04_still_reg_FWF.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask(subpath, fwfpath, threshold=0.99):\n",
    "    \"\"\"\n",
    "    By looking at the imgs generated, we have found out there are some regions that should not be included. Since they have values higher than 1.0\n",
    "    And we have found out voxels have NDI and ODI values, while that voxel has GROUND TRUTH FWF 1.0\n",
    "    This should indicate that that voxel should not even be included in the training\n",
    "    Therefore we want to filter the each subject's mask first, by using their corresponding GROUND TRUTH FWF\n",
    "\n",
    "    Args:\n",
    "        subpath (string): the path of the subject folder\n",
    "        fwfpath (string): the path of the corresponding fwf file\n",
    "        threshold (float): the thresholds to be used to filter of the mask,\n",
    "                           a stringnent threshold would be 0.9, the least stringnent threshold is 1.0\n",
    "                           by default, it is set to 0.99\n",
    "    \"\"\"\n",
    "    # fetch the mask data\n",
    "    img_mask = nib.load(subpath+'mask-e.nii')\n",
    "    original_mask = img_mask.get_fdata()\n",
    "    original_affine = img_mask.affine\n",
    "    shape = original_mask.shape # retain the shape of the mask\n",
    "    origin_nonzeros = np.count_nonzero(original_mask)\n",
    "    print('original mask has: ' + str(origin_nonzeros) + ' of nonzero voxels')\n",
    "    # fetch the FWF data\n",
    "    fwf = nib.load(fwfpath).get_fdata()\n",
    "    # filter\n",
    "    mask = original_mask.flatten() # this makes a copy of the orginal mask\n",
    "    fwf = fwf.reshape(mask.shape[0]) # reshape fwf to the corresponding shape\n",
    "    for i in range(len(mask)):\n",
    "        # if fwf has high value, means there is no tissue\n",
    "        # therefore, the voxel should be excluded\n",
    "        if fwf[i] >= threshold:\n",
    "            mask[i] = 0.0\n",
    "    # reshape mask back\n",
    "    mask = mask.reshape(shape)\n",
    "    filter_nonzeros = np.count_nonzero(mask)\n",
    "    print('filtered mask has: ' +str(filter_nonzeros) + ' of nonzero voxels')\n",
    "    # save the mask\n",
    "    filter_img = nib.Nifti1Image(mask, original_affine)\n",
    "    nib.save(filter_img, subpath+'filtered_mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1778b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above code to filter each subject's mask. Store as filtered_mask.nii in each subject folder\n",
    "filter_mask(s01_path, s01_FWF_path)\n",
    "filter_mask(s02_path, s02_FWF_path)\n",
    "filter_mask(s03_path, s04_FWF_path)\n",
    "filter_mask(s04_path, s03_FWF_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd11d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered mask path for each subject\n",
    "s01_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/filtered_mask.nii'\n",
    "s02_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/filtered_mask.nii'\n",
    "s03_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s03_still_reg/filtered_mask.nii'\n",
    "s04_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s04_still_reg/filtered_mask.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a235166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple test to verify the algorithm mask_nii_data from utils.nii_utils correctly generates the 1x1 patch from (a) given volume(s) DWI\n",
    "s02_mask_data = nib.load(s02_mask_path).get_fdata()\n",
    "print(s02_mask_data.shape)\n",
    "# generate a random mask\n",
    "random_mask = np.zeros((s02_mask_data.shape[0],s02_mask_data.shape[1], s02_mask_data.shape[2]))\n",
    "print(random_mask.shape)\n",
    "# select some pixels' values in the random_mask turn into 1\n",
    "# randomly select 4 paris of x, y value\n",
    "for i in range(4):\n",
    "    rand_x = np.random.randint(low=0, high=s02_mask_data.shape[0])\n",
    "    rand_y = np.random.randint(low=0, high=s02_mask_data.shape[1])\n",
    "    rand_z = np.random.randint(low=0, high=s02_mask_data.shape[2])\n",
    "    # set the corresponding pixel to have value 1\n",
    "    random_mask[rand_x][rand_y][rand_z] = 1\n",
    "# by this, we know the ground truth for this test. The number of 1s in the mask = the number of 1x1 pacth generated from the algorithm\n",
    "# we apply the random mask onto the s02_mask\n",
    "data = mask_nii_data(data=s02_mask_data, mask=random_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48019d0",
   "metadata": {},
   "source": [
    "<strong>Interpret the result from the algorithm test.</strong>\n",
    "The s02_mask has only one volume of shape (84,84,50). The random mask has a shape (84,84,50).</br>\n",
    "We randomly turned 4 pixels in the random mask to 1. Then apply the random mask to the s02_mask.</br>\n",
    "<strong>What we expect to see, there should be 4 patches generated for each volume of s02_mask.</strong></br>\n",
    "Results show that the data afer masking (by the random mask) has a shape (4,1). Where 4 represents the number of 1x1 patches and 1 represent the volume of s02_mask.</br>\n",
    "Therefore, it suggests the algorithm works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6068e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate base datasets for each subject\n",
    "\"\"\"\n",
    "ltype = ['N','O','F','A']\n",
    "for l in ltype:\n",
    "    print('Generating basedataset for label: ' + l)\n",
    "    cmd = '--base --label_type ' + l + ' --subjects s01_still s02_still s03_still_reg s04_still_reg'\n",
    "    args = data_parser().parse_args(cmd.split())\n",
    "    generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using nib to fetch the ground truth img\n",
    "\"\"\"\n",
    "#load the truth data for subject 1\n",
    "s01_NDI_img = nib.load(s01_NDI_path)\n",
    "s01_ODI_img = nib.load(s01_ODI_path)\n",
    "s01_FWF_img = nib.load(s01_FWF_path)\n",
    "s01_NDI_affine = s01_NDI_img.affine\n",
    "s01_ODI_affine = s01_ODI_img.affine\n",
    "s01_FWF_affine = s01_FWF_img.affine\n",
    "s01_NDI_img_data = s01_NDI_img.get_fdata()\n",
    "s01_ODI_img_data = s01_ODI_img.get_fdata()\n",
    "s01_FWF_img_data = s01_FWF_img.get_fdata()\n",
    "#load the truth data for subject 2\n",
    "s02_NDI_img = nib.load(s02_NDI_path)\n",
    "s02_ODI_img = nib.load(s02_ODI_path)\n",
    "s02_FWF_img = nib.load(s02_FWF_path)\n",
    "s02_NDI_affine = s02_NDI_img.affine\n",
    "s02_ODI_affine = s02_ODI_img.affine\n",
    "s02_FWF_affine = s02_FWF_img.affine\n",
    "s02_NDI_img_data = s02_NDI_img.get_fdata()\n",
    "s02_ODI_img_data = s02_ODI_img.get_fdata()\n",
    "s02_FWF_img_data = s02_FWF_img.get_fdata()\n",
    "# load the truth data for subject 3\n",
    "s03_NDI_img = nib.load(s03_NDI_path)\n",
    "s03_ODI_img = nib.load(s03_ODI_path)\n",
    "s03_FWF_img = nib.load(s03_FWF_path)\n",
    "s03_NDI_affine = s03_NDI_img.affine\n",
    "s03_ODI_affine = s03_ODI_img.affine\n",
    "s03_FWF_affine = s03_FWF_img.affine\n",
    "s03_NDI_img_data = s03_NDI_img.get_fdata()\n",
    "s03_ODI_img_data = s03_ODI_img.get_fdata()\n",
    "s03_FWF_img_data = s03_FWF_img.get_fdata()\n",
    "# load the truth data for subject 4\n",
    "s04_NDI_img = nib.load(s04_NDI_path)\n",
    "s04_ODI_img = nib.load(s04_ODI_path)\n",
    "s04_FWF_img = nib.load(s04_FWF_path)\n",
    "s04_NDI_affine = s04_NDI_img.affine\n",
    "s04_ODI_affine = s04_ODI_img.affine\n",
    "s04_FWF_affine = s04_FWF_img.affine\n",
    "s04_NDI_img_data = s04_NDI_img.get_fdata()\n",
    "s04_ODI_img_data = s04_ODI_img.get_fdata()\n",
    "s04_FWF_img_data = s04_FWF_img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0dc610",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae9c93",
   "metadata": {},
   "source": [
    "<strong>NDI</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6eacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset NDI for ANN.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still s02_still s03_still_reg s04_still_reg --fc1d --label_type N\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a5ba4",
   "metadata": {},
   "source": [
    "<strong>\n",
    "Interpret this result.\n",
    "</strong> \n",
    "After the mask is applied to 96 volumes of DWI imgs, for each volume of img, there are 81882 1x1 patches (i.e. voxels) generated. Therefore, in total there are 81882x96=7860672 values as training dataset. <br/>\n",
    "For each masked voxel, there is a corresponding NDI value. Therefore, the number of NDI values is the same as the number of masked voxels (82889). Becasue we are examine NDI only, hence only one value associated with each masked voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset for 2D CNN\n",
    "cmd = \"--subjects s01_still s02_still s03_still_reg s04_still_reg --conv2d --label_type N\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63437892",
   "metadata": {},
   "source": [
    "<strong>\n",
    "Interpret the result\n",
    "</strong>\n",
    "The masked voxels are 81634. For each masked voxel, there is a 3x3 patch which includes this masked voxel at the centre of the patch; but also including its 8 neighbouring voxels. Each masked voxel has 96 volumes of the 3x3 patch. Therefore, in total there are 81634 x 3 x 3 x 96 = 70531776 values as the training dataset.<br/>\n",
    "Herein, because we only examine NDI. For each masked voxel, there is a corresponded predicted NDI value. Hence the number of masked voxels is the same for label and data. The label size is 1x1 because it is the NDI parameter for the masked voxel. The masked voxel has a size 1x1. And there is only one of this value for each masked voxel, since only NDI is considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset for 3D CNN\n",
    "cmd = \"--subjects s01_still s02_still s03_still_reg s04_still_reg --conv3d --label_type N\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54be8b2",
   "metadata": {},
   "source": [
    "<strong>\n",
    "Interpret the result\n",
    "</strong>\n",
    "The masked voxels are 81634. For each masked voxel, there is a 3x3x3 patch which includes this masked voxel at the centre of the patch; but also including its 26 neighbouring voxels. Each masked voxel has 96 volumes of 3x3x3 patch. Therefore, in total there are 81634 x 3 x 3 x 3 x 96 = 211595328 values as the training dataset.<br/>\n",
    "Herein, because we only examine NDI. For each masked voxel, there is a corresponded predicted NDI value. Hence the number of masked voxels is the same for label and data. The label size is 1x1x1 because it is the NDI parameter for the masked voxel. The masked voxel has a size 1x1x1. And there is only one of this value for each masked voxel, since only NDI is considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccc54bc",
   "metadata": {},
   "source": [
    "<h4>Training</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1c5d3",
   "metadata": {},
   "source": [
    "<strong>\n",
    "The split between validation dataset and the training dataset is 5:5<br/>\n",
    "The learning rate is 0.0001 to ensure a smooth learning<br/>\n",
    "Herein, at most 6 hidden fully connected layers are trained.<br/>\n",
    "Loss curve for each training is plotted.<br/>\n",
    "The test result is also generated -- evaluating the RMSE and SSIM between pred and reference.<br/>\n",
    "The reference image and the genereated image are displayed side by side.</br>\n",
    "The difference map between the ref img and the pred img is also generated\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25594ae7",
   "metadata": {},
   "source": [
    "<strong>1 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef136633",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer training\n",
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer testing\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759195dd",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer training\n",
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer testing\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75774c37",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer training\n",
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ae97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer testing\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f950c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_NDI_img_data)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'fc1d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv2d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv3d',layer, s02_NDI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbde8e5",
   "metadata": {},
   "source": [
    "<strong>2 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2580b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b283c",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f26c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08210bce",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7d7a2",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928deed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_NDI_img_data)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'fc1d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv2d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv3d',layer, s02_NDI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e7c2ff",
   "metadata": {},
   "source": [
    "<strong>3 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e408a6",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e70228",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9cdb44",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678aaa42",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f508c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcd5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_NDI_img_data)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'fc1d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv2d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv3d',layer, s02_NDI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82666a",
   "metadata": {},
   "source": [
    "<strong>4 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e23c9f",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda8787",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cccec9",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_NDI_img_data)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'fc1d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv2d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv3d',layer, s02_NDI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31fea7",
   "metadata": {},
   "source": [
    "<strong>5 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7abd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a68c953",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9fa568",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a060d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7baa17f",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282fe9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_NDI_img_data)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'fc1d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv2d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv3d',layer, s02_NDI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2f37c",
   "metadata": {},
   "source": [
    "<strong>6 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d073b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52379a36",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72898fa2",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15cad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989a426",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type N'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type N'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c584a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_NDI_img_data)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'fc1d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv2d',layer, s02_NDI_affine)\n",
    "visualise1(s02_NDI_img_data, 96, 's02_still', 'conv3d',layer, s02_NDI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f57287",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784c57d",
   "metadata": {},
   "source": [
    "<strong>ODI</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fe485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset ODI for ANN.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still s02_still s03_still_reg s04_still_reg --fc1d --label_type O\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e20dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset ODI for 2D CNN.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still s02_still s03_still_reg s04_still_reg --conv2d --label_type O\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset ODI for 3D CNN.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still s02_still s03_still_reg s04_still_reg --conv3d --label_type O\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11875f1",
   "metadata": {},
   "source": [
    "<strong>1 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04822ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55874f64",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9277e0",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4253a",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'fc1d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv2d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv3d',layer, s02_ODI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4146c5",
   "metadata": {},
   "source": [
    "<strong>2 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32901ace",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f82fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9d701",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cffa4a",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab622978",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2384a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'fc1d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv2d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv3d',layer, s02_ODI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8400d",
   "metadata": {},
   "source": [
    "<strong>3 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04e053",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f82fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889dfd6b",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6f6cd4",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95345c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f895dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'fc1d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv2d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv3d',layer, s02_ODI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb50e41",
   "metadata": {},
   "source": [
    "<strong>4 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5402328",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac5707",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac5a7e",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b32f7",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809fdb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f34d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'fc1d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv2d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv3d',layer, s02_ODI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d0fde",
   "metadata": {},
   "source": [
    "<strong>5 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c5369",
   "metadata": {},
   "source": [
    "<strong>ANN</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c532f",
   "metadata": {},
   "source": [
    "<strong>2D CNN</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c28435",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708d097",
   "metadata": {},
   "source": [
    "<strong>3D CNN</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5feac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'fc1d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv2d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv3d',layer, s02_ODI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adebe982",
   "metadata": {},
   "source": [
    "<strong>6 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e87821",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a023a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c37dbd",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29859a8f",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type O'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type O'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8054eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_ODI_img_data)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'fc1d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv2d',layer, s02_ODI_affine)\n",
    "visualise2(s02_ODI_img_data, 96, 's02_still', 'conv3d',layer, s02_ODI_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9647b08",
   "metadata": {},
   "source": [
    "<strong>FWF</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset for ANNc\n",
    "cmd = \"--subjects s01_still s02_still s03_still_reg s04_still_reg --fc1d --label_type F\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset for 2D CNN\n",
    "cmd = \"--subjects s01_still s02_still s03_still_reg s04_still_reg --conv2d --label_type F\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset for 3D CNN\n",
    "cmd = \"--subjects s01_still s02_still s03_still_reg s04_still_reg --conv3d --label_type F\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12e8066",
   "metadata": {},
   "source": [
    "<strong>1 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf24452",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67617667",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bc34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1e540",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49981941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'fc1d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv2d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv3d',layer, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97167339",
   "metadata": {},
   "source": [
    "<strong>2 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef9791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f81b9b",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa7aa0",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55626b18",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528bcf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'fc1d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv2d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv3d',layer, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890d158",
   "metadata": {},
   "source": [
    "<strong>3 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ecec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c2f2f",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c76799",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b89bb1",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3dbf2d",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'fc1d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv2d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv3d',layer, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b0ca14",
   "metadata": {},
   "source": [
    "<strong>4 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867499b",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb565be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191889c7",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492dd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c5d0a",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e71737",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016334c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'fc1d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv2d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv3d',layer, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9025a2fb",
   "metadata": {},
   "source": [
    "<strong>5 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b23a5",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9ce9b0",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c38c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128fbe9",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a73b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9135bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'fc1d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv2d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv3d',layer, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51332804",
   "metadata": {},
   "source": [
    "<strong>6 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c682ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5817a6",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa582089",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model fc1d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model fc1d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c12912",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c624a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv2d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv2d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a90be",
   "metadata": {},
   "source": [
    "3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90acd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '--train_subjects '+train_subject+' --model conv3d --layer '+layer+' --train --label_type F'\n",
    "plot_loss(cmd)\n",
    "for test_subject in test_subjects:\n",
    "    cmd = '--test_subjects '+test_subject+' --model conv3d --layer '+layer+' --label_type F'\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "visualise0(s02_FWF_img_data)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'fc1d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv2d',layer, s02_FWF_affine)\n",
    "visualise3(s02_FWF_img_data, 96, 's02_still', 'conv3d',layer, s02_FWF_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3332f6",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee625bd",
   "metadata": {},
   "source": [
    "<h4>Test the performace of each network to generate each parameter with varied number of DWI as input size</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c6a8b",
   "metadata": {},
   "source": [
    "Each network (ANN, 2D CNN and 3D CNN) should be implemented with 4 hidden layers. The choice is suggested from the obtained results from the previous experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a025d",
   "metadata": {},
   "source": [
    "<h4>Training</h4><br/>\n",
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80867042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of parameters required to be trained and tested\n",
    "params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# train\n",
    "for param in params:\n",
    "    # vary the input size; in this case becasue I know the max input size is 96\n",
    "    for i in np.arange(start=6, stop=97, step=10):\n",
    "        # specify the param to be trained and the size of the input\n",
    "        train_cmd = \"--train_subjects s01_still --model fc1d --layer 4 --train --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "        # for each training, plot the corresponding loss graph\n",
    "        plot_loss(train_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of parameters required to be trained and tested\n",
    "params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# test\n",
    "for param in params:\n",
    "    # vary the input size; in this case becasue I know the max input size is 96\n",
    "    for i in np.arange(start=6, stop=97, step=10):\n",
    "        # specify the param to be tested and the size of the test data\n",
    "        print(i)\n",
    "        test_cmd = \"--test_subjects s02_still --model fc1d --layer 4 --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "        args = model_parser().parse_args(test_cmd.split())\n",
    "        # test the trained model\n",
    "        test_model(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc311e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each derived image\n",
    "# specify the parameters\n",
    "params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "ref_img = [s02_NDI_img, s02_ODI_img, s02_FWF_img] # this is the ref img data list\n",
    "ref_img_data = [s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data] # this is the ref img data list\n",
    "# iterate, so plot each param in order\n",
    "for i in range (len(params)):\n",
    "    # plot the reference img first\n",
    "    ref_slice_0 = ref_img_data[i][26, :, :]\n",
    "    ref_slice_1 = ref_img_data[i][:, 30, :]\n",
    "    ref_slice_2 = ref_img_data[i][:, :, 16]\n",
    "    show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "    plt.suptitle(\"Center slices for s02_still_\" + params[i] + \" reference image\")\n",
    "    \n",
    "    affine = ref_img[i].affine\n",
    "    \n",
    "    for j in np.arange(start=6, stop=97, step=10):\n",
    "        # plot the predicted imgs for different input size\n",
    "        pred_path = '../Net/nii/s02_still-' + str(j)+'-fc1d-patch_1-base_1-layer_4-label_'+params[i]+'.nii'\n",
    "        # load the img\n",
    "        pred_img = nib.load(pred_path)\n",
    "        # fetch the data\n",
    "        pred_data = pred_img.get_fdata()\n",
    "\n",
    "        # plot the pred img\n",
    "        pred0 = pred_data[26, :, :]\n",
    "        pred1 = pred_data[:, 30, :]\n",
    "        pred2 = pred_data[:, :, 16]\n",
    "        show_slices([pred0, pred1, pred2])\n",
    "        plt.suptitle(\"Center slices for s02_still_\" + params[i] + \" predicted image by ANN, input size=\"+str(j))\n",
    "\n",
    "        # plot the difference img\n",
    "        diff0 = ref_slice_0 - pred0\n",
    "        diff1 = ref_slice_1 - pred1\n",
    "        diff2 = ref_slice_2 - pred2\n",
    "        show_slices([diff0, diff1, diff2], grayscale=False)\n",
    "        plt.suptitle('Difference map')\n",
    "\n",
    "        diff_img_np = ref_img_data[i] - pred_data\n",
    "        diff_img = nib.Nifti1Image(diff_img_np, affine)\n",
    "        nib.save(diff_img, '../Net/nii/s02_still-' + str(j)+'-fc1d-patch_1-base_1-layer_4-label_'+params[i]+'_difference.nii')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f95297",
   "metadata": {},
   "source": [
    "5 Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the list of parameters required to be trained and tested\n",
    "# params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# # train\n",
    "# for param in params:\n",
    "#     # vary the input size; in this case becasue I know the max input size is 96\n",
    "#     for i in np.arange(start=6, stop=97, step=10):\n",
    "#         # specify the param to be trained and the size of the input\n",
    "#         train_cmd = \"--train_subjects s01_still --model fc1d --layer 5 --train --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "#         # for each training, plot the corresponding loss graph\n",
    "#         plot_loss(train_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8135a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the list of parameters required to be trained and tested\n",
    "# params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# # test\n",
    "# for param in params:\n",
    "#     # vary the input size; in this case becasue I know the max input size is 96\n",
    "#     for i in np.arange(start=6, stop=97, step=10):\n",
    "#         # specify the param to be tested and the size of the test data\n",
    "#         print(i)\n",
    "#         test_cmd = \"--test_subjects s02_still --model fc1d --layer 5 --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "#         args = model_parser().parse_args(test_cmd.split())\n",
    "#         # test the trained model\n",
    "#         test_model(args) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c4d69",
   "metadata": {},
   "source": [
    "2D CNN<br/>\n",
    "repeat exactly the same process as above, but change the network to 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98025db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of parameters required to be trained and tested\n",
    "params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# train\n",
    "for param in params:\n",
    "    # vary the input size; in this case becasue I know the max input size is 96\n",
    "    for i in np.arange(start=6, stop=97, step=10):\n",
    "        # specify the param to be trained and the size of the input\n",
    "        train_cmd = \"--train_subjects s01_still --model conv2d --layer 4 --train --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "        # for each training, plot the corresponding loss graph\n",
    "        plot_loss(train_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a41aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of parameters required to be trained and tested\n",
    "params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# test\n",
    "for param in params:\n",
    "    # vary the input size; in this case becasue I know the max input size is 96\n",
    "    for i in np.arange(start=6, stop=97, step=10):\n",
    "        # specify the param to be tested and the size of the test data\n",
    "        test_cmd = \"--test_subjects s02_still --model conv2d --layer 4 --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "        args = model_parser().parse_args(test_cmd.split())\n",
    "        # test the trained model\n",
    "        test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec19376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each derived image\n",
    "# specify the parameters\n",
    "params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "ref_img = [s02_NDI_img, s02_ODI_img, s02_FWF_img] # this is the ref img data list\n",
    "ref_img_data = [s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data] # this is the ref img data list\n",
    "# iterate, so plot each param in order\n",
    "for i in range (len(params)):\n",
    "    # plot the reference img first\n",
    "    ref_slice_0 = ref_img_data[i][26, :, :]\n",
    "    ref_slice_1 = ref_img_data[i][:, 30, :]\n",
    "    ref_slice_2 = ref_img_data[i][:, :, 16]\n",
    "    show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "    plt.suptitle(\"Center slices for s02_still_\" + params[i] + \" reference image\")\n",
    "    \n",
    "    affine = ref_img[i].affine\n",
    "    \n",
    "    for j in np.arange(start=6, stop=97, step=10):\n",
    "        # plot the predicted imgs for different input size\n",
    "        pred_path = '../Net/nii/s02_still-' + str(j)+'-conv2d-patch_3-base_1-layer_4-label_'+params[i]+'.nii'\n",
    "        # load the img\n",
    "        pred_img = nib.load(pred_path)\n",
    "        # fetch the data\n",
    "        pred_data = pred_img.get_fdata()\n",
    "\n",
    "        # plot the pred img\n",
    "        pred0 = pred_data[26, :, :]\n",
    "        pred1 = pred_data[:, 30, :]\n",
    "        pred2 = pred_data[:, :, 16]\n",
    "        show_slices([pred0, pred1, pred2])\n",
    "        plt.suptitle(\"Center slices for s02_still_\" + params[i] + \" predicted image by 2D CNN, input size=\"+str(j))\n",
    "\n",
    "        # plot the difference img\n",
    "        diff0 = ref_slice_0 - pred0\n",
    "        diff1 = ref_slice_1 - pred1\n",
    "        diff2 = ref_slice_2 - pred2\n",
    "        show_slices([diff0, diff1, diff2], grayscale=False)\n",
    "        plt.suptitle('Difference map')\n",
    "\n",
    "        diff_img_np = ref_img_data[i] - pred_data\n",
    "        diff_img = nib.Nifti1Image(diff_img_np, affine)\n",
    "        nib.save(diff_img, '../Net/nii/s02_still-' + str(j)+'-conv2d-patch_3-base_1-layer_4-label_'+params[i]+'_difference.nii')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4008673",
   "metadata": {},
   "source": [
    "5 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the list of parameters required to be trained and tested\n",
    "# params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# # train\n",
    "# for param in params:\n",
    "#     # vary the input size; in this case becasue I know the max input size is 96\n",
    "#     for i in np.arange(start=6, stop=97, step=10):\n",
    "#         # specify the param to be trained and the size of the input\n",
    "#         train_cmd = \"--train_subjects s01_still --model conv2d --layer 5 --train --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "#         # for each training, plot the corresponding loss graph\n",
    "#         plot_loss(train_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f287e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the list of parameters required to be trained and tested\n",
    "# params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# # test\n",
    "# for param in params:\n",
    "#     # vary the input size; in this case becasue I know the max input size is 96\n",
    "#     for i in np.arange(start=6, stop=97, step=10):\n",
    "#         # specify the param to be tested and the size of the test data\n",
    "#         test_cmd = \"--test_subjects s02_still --model conv2d --layer 5 --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "#         args = model_parser().parse_args(test_cmd.split())\n",
    "#         # test the trained model\n",
    "#         test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a6e30",
   "metadata": {},
   "source": [
    "3D CNN<br/>\n",
    "repeat the same process as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of parameters required to be trained and tested\n",
    "params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# train\n",
    "for param in params:\n",
    "    # vary the input size; in this case becasue I know the max input size is 96\n",
    "    for i in np.arange(start=6, stop=97, step=10):\n",
    "        # specify the param to be trained and the size of the input\n",
    "        train_cmd = \"--train_subjects s01_still --model conv3d --layer 4 --train --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "        # for each training, plot the corresponding loss graph\n",
    "        plot_loss(train_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of parameters required to be trained and tested\n",
    "params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# test\n",
    "for param in params:\n",
    "    # vary the input size; in this case becasue I know the max input size is 96\n",
    "    for i in np.arange(start=6, stop=97, step=10):\n",
    "        # specify the param to be tested and the size of the test data\n",
    "        test_cmd = \"--test_subjects s02_still --model conv3d --layer 4 --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "        args = model_parser().parse_args(test_cmd.split())\n",
    "        # test the trained model\n",
    "        test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ef0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each derived image\n",
    "# specify the parameters\n",
    "params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "ref_img = [s02_NDI_img, s02_ODI_img, s02_FWF_img] # this is the ref img data list\n",
    "ref_img_data = [s02_NDI_img_data, s02_ODI_img_data, s02_FWF_img_data] # this is the ref img data list\n",
    "# iterate, so plot each param in order\n",
    "for i in range (len(params)):\n",
    "    # plot the reference img first\n",
    "    ref_slice_0 = ref_img_data[i][26, :, :]\n",
    "    ref_slice_1 = ref_img_data[i][:, 30, :]\n",
    "    ref_slice_2 = ref_img_data[i][:, :, 16]\n",
    "    show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "    plt.suptitle(\"Center slices for s02_still_\" + params[i] + \" reference image\")\n",
    "    \n",
    "    affine = ref_img[i].affine\n",
    "    \n",
    "    for j in np.arange(start=6, stop=97, step=10):\n",
    "        # plot the predicted imgs for different input size\n",
    "        pred_path = '../Net/nii/s02_still-' + str(j)+'-conv3d-patch_3-base_1-layer_4-label_'+params[i]+'.nii'\n",
    "        # load the img\n",
    "        pred_img = nib.load(pred_path)\n",
    "        # fetch the data\n",
    "        pred_data = pred_img.get_fdata()\n",
    "\n",
    "        # plot the pred img\n",
    "        pred0 = pred_data[26, :, :]\n",
    "        pred1 = pred_data[:, 30, :]\n",
    "        pred2 = pred_data[:, :, 16]\n",
    "        show_slices([pred0, pred1, pred2])\n",
    "        plt.suptitle(\"Center slices for s02_still_\" + params[i] + \" predicted image by 3D CNN, input size=\"+str(j))\n",
    "\n",
    "        # plot the difference img\n",
    "        diff0 = ref_slice_0 - pred0\n",
    "        diff1 = ref_slice_1 - pred1\n",
    "        diff2 = ref_slice_2 - pred2\n",
    "        show_slices([diff0, diff1, diff2], grayscale=False)\n",
    "        plt.suptitle('Difference map')\n",
    "\n",
    "        diff_img_np = ref_img_data[i] - pred_data\n",
    "        diff_img = nib.Nifti1Image(diff_img_np, affine)\n",
    "        nib.save(diff_img, '../Net/nii/s02_still-' + str(j)+'-conv3d-patch_1-base_1-layer_4-label_'+params[i]+'_difference.nii')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da56f57d",
   "metadata": {},
   "source": [
    "5 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c083324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the list of parameters required to be trained and tested\n",
    "# params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# # train\n",
    "# for param in params:\n",
    "#     # vary the input size; in this case becasue I know the max input size is 96\n",
    "#     for i in np.arange(start=6, stop=97, step=10):\n",
    "#         # specify the param to be trained and the size of the input\n",
    "#         train_cmd = \"--train_subjects s01_still --model conv3d --layer 5 --train --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "#         # for each training, plot the corresponding loss graph\n",
    "#         plot_loss(train_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the list of parameters required to be trained and tested\n",
    "# params = ['NDI', 'ODI', 'FWF'] # this is for NODDI\n",
    "# # test\n",
    "# for param in params:\n",
    "#     # vary the input size; in this case becasue I know the max input size is 96\n",
    "#     for i in np.arange(start=6, stop=97, step=10):\n",
    "#         # specify the param to be tested and the size of the test data\n",
    "#         test_cmd = \"--test_subjects s02_still --model conv3d --layer 5 --label_type \" + param[0] + \" --DWI \" + str(i)\n",
    "#         args = model_parser().parse_args(test_cmd.split())\n",
    "#         # test the trained model\n",
    "#         test_model(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
