{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>New Experiment 2: Random rejection of motion-free subjects</h1>\n",
    "In this notebook, random rejection tests were conducted using data from S1 in the still condition. The generalisation tests were conducted over S2. Each time we fix the number of retained volumes N. We randomly select N volumes from a subject's data, then we train our proposed model over this sample. At testing, we applied the same rejection scheme to S2, then test over the subset of S2.</br>\n",
    "We would like to show this proposed model is robust, by which it is independent of 1. The proportion of discarded volumes and 2. The different combinations of b-values.</br>\n",
    "<h2>Packages</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "packages that does conventional model fitting\n",
    "\"\"\"\n",
    "import amico\n",
    "\"\"\"\n",
    "packages that generate train/test dataset\n",
    "\"\"\"\n",
    "from FormatData import generate_data, parser as data_parser\n",
    "\"\"\"\n",
    "packages that trains network\n",
    "\"\"\"\n",
    "from Training import train_network\n",
    "from utils.model import parser as model_parser\n",
    "\"\"\"\n",
    "packages that test network\n",
    "\"\"\"\n",
    "from Testing import test_model\n",
    "\"\"\"\n",
    "packages that produce the rejection shceme\n",
    "\"\"\"\n",
    "from filter_qa import parser as filter_parser, load_eddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "packages that handle graphs\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm, LinearSegmentedColormap\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from utils import calc_ssim\n",
    "%matplotlib inline\n",
    "def plot_loss(cmd):\n",
    "    \"\"\"\n",
    "    A function that used to plot the loss curve for the trained network.\n",
    "    Args:\n",
    "        cmd: String, the command line in the terminal\n",
    "    \"\"\"\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    history = train_network(args)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def show_slices(slices, grayscale=True):\n",
    "    \"\"\"\n",
    "    Function to display the slices\n",
    "\n",
    "    Args:\n",
    "        slices (list): a list of 2d ndarray that contains the data to be displayed\n",
    "        grayscale (bool, optional): True, if diplay grayscale img. Defaults to True.\n",
    "    \"\"\"    \n",
    "    fig, axes = plt.subplots(1, len(slices), figsize=(10,10))\n",
    "    cax = fig.add_axes([0, 0, .3, .3])\n",
    "    for i, slice in enumerate(slices):\n",
    "        # use grayscale for displaying ref and pred imgs:\n",
    "        if grayscale:\n",
    "            cmap = plt.get_cmap('gray')\n",
    "            cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "            cmap = LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "            bounds = np.arange(0, 1.0, .01)\n",
    "            idx = np.searchsorted(bounds, 0)\n",
    "            bounds = np.insert(bounds, idx, 0)\n",
    "            norm = BoundaryNorm(bounds, cmap.N)\n",
    "            im = axes[i].imshow(slice.T, cmap=cmap, origin=\"lower\", interpolation='none', norm=norm)\n",
    "        else:\n",
    "            # define the colormap\n",
    "            cmap = plt.get_cmap('bwr')\n",
    "            # extract all colors from the .jet map\n",
    "            cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "            # create the new map\n",
    "            cmap = LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "            # define the bins and normalize and forcing 0 to be part of the colorbar\n",
    "            # define the min and max to be -1 and +1 respectively\n",
    "            bounds = np.arange(-0.5, 0.5, .01)\n",
    "            idx = np.searchsorted(bounds, 0)\n",
    "            bounds = np.insert(bounds, idx, 0)\n",
    "            norm = BoundaryNorm(bounds, cmap.N)\n",
    "            im = axes[i].imshow(slice.T, cmap=cmap, origin=\"lower\", interpolation='none', norm=norm)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "def scale(img):\n",
    "    # for i in range(img.shape[0]):\n",
    "    #     for j in range(img.shape[1]):\n",
    "    #         img[i][j] = ((img[i][j]+1)/2)*255\n",
    "    return img\n",
    "\n",
    "def compare_simi(pred, ref):\n",
    "    return calc_ssim(pred, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(ref_ndi, ref_odi, ref_fwf, retained_vol, subject, model, layer, affine1, affine2, affine3):\n",
    "    \"\"\"\n",
    "    Function to visualise the imgs and difference maps\n",
    "\n",
    "    Args:\n",
    "        ref_ndi (ndarray): the reference NDI data\n",
    "        ref_odi (ndarray): the reference ODI data\n",
    "        ref_fwf (ndarray): the reference FWF data\n",
    "        retained_vol (int): the number of volumes retained after rejection\n",
    "        subject (string): the subject that is examined\n",
    "        model (string): the model used\n",
    "        layer (int): the number of layers for the network\n",
    "    \"\"\"\n",
    "    patch = 3\n",
    "    if model == 'fc1d':\n",
    "        patch = 1\n",
    "\n",
    "    print(patch)\n",
    "    print(model)\n",
    "    # visualise the ref imgs\n",
    "    refNDI0 = ref_ndi[26, :, :]\n",
    "    refNDI1 = ref_ndi[:, 30, :]\n",
    "    refNDI2 = ref_ndi[:, :, 16]\n",
    "    show_slices([refNDI0, refNDI1, refNDI2])\n",
    "    plt.suptitle(\"Center slices for NDI reference image\")\n",
    "\n",
    "    refODI0 = ref_odi[26, :, :]\n",
    "    refODI1 = ref_odi[:, 30, :]\n",
    "    refODI2 = ref_odi[:, :, 16]\n",
    "    show_slices([refODI0, refODI1, refODI2])\n",
    "    plt.suptitle(\"Center slices for ODI reference image\")\n",
    "\n",
    "    refFWF0 = ref_fwf[26, :, :]\n",
    "    refFWF1 = ref_fwf[:, 30, :]\n",
    "    refFWF2 = ref_fwf[:, :, 16]\n",
    "    show_slices([refFWF0, refFWF1, refFWF2])\n",
    "    plt.suptitle(\"Center slices for FWF reference image\")\n",
    "\n",
    "    # visualise the pred imgs produced at varied input size\n",
    "    ndi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDI.nii'\n",
    "    odi_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODI.nii'\n",
    "    fwf_path = '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWF.nii'\n",
    "    ndi_img = nib.load(ndi_path)\n",
    "    ndi_data = ndi_img.get_fdata()\n",
    "    odi_img = nib.load(odi_path)\n",
    "    odi_data = odi_img.get_fdata()\n",
    "    fwf_img = nib.load(fwf_path)\n",
    "    fwf_data = fwf_img.get_fdata()\n",
    "\n",
    "    ndi0 = ndi_data[26, :, :]\n",
    "    ndi1 = ndi_data[:, 30, :]\n",
    "    ndi2 = ndi_data[:, :, 16]\n",
    "    show_slices([ndi0, ndi1, ndi2])\n",
    "    plt.suptitle('Center slices for NDI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, ndidiff) = compare_ssim(ndi_data, ref_ndi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for ndi is: ' + str(score))\n",
    "\n",
    "    odi0 = odi_data[26, :, :]\n",
    "    odi1 = odi_data[:, 30, :]\n",
    "    odi2 = odi_data[:, :, 16]\n",
    "    show_slices([odi0, odi1, odi2])\n",
    "    plt.suptitle('Center slices for ODI predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, odidiff) = compare_ssim(odi_data, ref_odi, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for odi is: ' + str(score))\n",
    "\n",
    "    fwf0 = fwf_data[26, :, :]\n",
    "    fwf1 = fwf_data[:, 30, :]\n",
    "    fwf2 = fwf_data[:, :, 16]\n",
    "    show_slices([fwf0, fwf1, fwf2])\n",
    "    plt.suptitle('Center slices for FWF predicted image by '+model+', input size='+str(retained_vol))\n",
    "    (score, fwfdiff) = compare_ssim(fwf_data, ref_fwf, full=True)\n",
    "    print(str(retained_vol)+'input size the ssim score for fwf is: ' + str(score))\n",
    "\n",
    "    # plot the difference map between the imgs by the lib\n",
    "    ndidiff0 = scale(refNDI0 - ndi0)\n",
    "    ndidiff1 = scale(refNDI1 - ndi1)\n",
    "    ndidiff2 = scale(refNDI2 - ndi2)\n",
    "    show_slices([ndidiff0, ndidiff1, ndidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map NDI\")\n",
    "\n",
    "    diff_img_np = ref_ndi - ndi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine1)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_NDI_difference.nii')\n",
    "\n",
    "    odidiff0 = scale(refODI0 - odi0)\n",
    "    odidiff1 = scale(refODI1 - odi1)\n",
    "    odidiff2 = scale(refODI2 - odi2)\n",
    "    show_slices([odidiff0, odidiff1, odidiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map ODI\")\n",
    "\n",
    "    diff_img_np = ref_odi - odi_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine2)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_ODI_difference.nii')\n",
    "\n",
    "    fwfdiff0 = scale(refFWF0 - fwf0)\n",
    "    fwfdiff1 = scale(refFWF1 - fwf1)\n",
    "    fwfdiff2 = scale(refFWF2 - fwf2)\n",
    "    show_slices([fwfdiff0, fwfdiff1, fwfdiff2], grayscale=False)\n",
    "    plt.suptitle(\"Difference map FWF\")\n",
    "\n",
    "    diff_img_np = ref_fwf - fwf_data\n",
    "    diff_img = nib.Nifti1Image(diff_img_np, affine3)\n",
    "    nib.save(diff_img, '../Net/nii/'+subject+'-'+str(retained_vol)+'-'+model+'-patch_'+str(patch)+'-base_1-layer_'+str(layer)+'-label_FWF_difference.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The class for parsing command line arguments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    \"\"\"\n",
    "    a class generate parser for cmd line args\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion-free subject path\n",
    "s01_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/'\n",
    "s02_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/'\n",
    "# motion-free target labels\n",
    "s01_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_NDI.nii'\n",
    "s02_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_NDI.nii'\n",
    "\n",
    "s01_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_ODI.nii'\n",
    "s02_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_ODI.nii'\n",
    "\n",
    "s01_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_FWF.nii'\n",
    "s02_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_FWF.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask(subpath, fwfpath, threshold=0.99):\n",
    "    \"\"\"\n",
    "    By looking at the imgs generated, we have found out there are some regions that should not be included. Since they have values higher than 1.0\n",
    "    And we have found out voxels have NDI and ODI values, while that voxel has GROUND TRUTH FWF 1.0\n",
    "    This should indicate that that voxel should not even be included in the training\n",
    "    Therefore we want to filter the each subject's mask first, by using their corresponding GROUND TRUTH FWF\n",
    "\n",
    "    Args:\n",
    "        subpath (string): the path of the subject folder\n",
    "        fwfpath (string): the path of the corresponding fwf file\n",
    "        threshold (float): the thresholds to be used to filter of the mask,\n",
    "                           a stringnent threshold would be 0.9, the least stringnent threshold is 1.0\n",
    "                           by default, it is set to 0.99\n",
    "    \"\"\"\n",
    "    # fetch the mask data\n",
    "    img_mask = nib.load(subpath+'mask-e.nii')\n",
    "    original_mask = img_mask.get_fdata()\n",
    "    original_affine = img_mask.affine\n",
    "    shape = original_mask.shape # retain the shape of the mask\n",
    "    origin_nonzeros = np.count_nonzero(original_mask)\n",
    "    print('original mask has: ' + str(origin_nonzeros) + ' of nonzero voxels')\n",
    "    # fetch the FWF data\n",
    "    fwf = nib.load(fwfpath).get_fdata()\n",
    "    # filter\n",
    "    mask = original_mask.flatten() # this makes a copy of the orginal mask\n",
    "    fwf = fwf.reshape(mask.shape[0]) # reshape fwf to the corresponding shape\n",
    "    for i in range(len(mask)):\n",
    "        # if fwf has high value, means there is no tissue\n",
    "        # therefore, the voxel should be excluded\n",
    "        if fwf[i] >= threshold:\n",
    "            mask[i] = 0.0\n",
    "    # reshape mask back\n",
    "    mask = mask.reshape(shape)\n",
    "    filter_nonzeros = np.count_nonzero(mask)\n",
    "    print('filtered mask has: ' +str(filter_nonzeros) + ' of nonzero voxels')\n",
    "    # save the mask\n",
    "    filter_img = nib.Nifti1Image(mask, original_affine)\n",
    "    nib.save(filter_img, subpath+'filtered_mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above code to filter each subject's mask. Store as filtered_mask.nii in each subject folder\n",
    "filter_mask(s01_path, s01_FWF_path)\n",
    "filter_mask(s02_path, s02_FWF_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered mask path for each subject\n",
    "s01_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/filtered_mask.nii'\n",
    "s02_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/filtered_mask.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate the base dataset for s01_still and s02_still for all NODDI parameters.\n",
    "\"\"\"\n",
    "cmd = \"--base --label_type A --subjects s01_still s02_still\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltype = 'A' # the NODDI parameter we want to estimate, where A stands for ALL\n",
    "model = 'conv3d'\n",
    "# firstly, the 3d cnn dataset is required to be generated.\n",
    "# the cmd line code for generating 3d cnn data\n",
    "cnn3ddata_cmd = '--subjects s01_still s02_still' + ' --label_type ' + ltype + ' --' + model\n",
    "cnn3ddata_args  = data_parser().parse_args(cnn3ddata_cmd.split())\n",
    "generate_data(cnn3ddata_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using nib to fetch the ground truth img\n",
    "\"\"\"\n",
    "#load the truth data for subject 1\n",
    "s01_NDI_img = nib.load(s01_NDI_path)\n",
    "s01_ODI_img = nib.load(s01_ODI_path)\n",
    "s01_FWF_img = nib.load(s01_FWF_path)\n",
    "s01_NDI_affine = s01_NDI_img.affine\n",
    "s01_ODI_affine = s01_ODI_img.affine\n",
    "s01_FWF_affine = s01_FWF_img.affine\n",
    "s01_NDI_img_data = s01_NDI_img.get_fdata()\n",
    "s01_ODI_img_data = s01_ODI_img.get_fdata()\n",
    "s01_FWF_img_data = s01_FWF_img.get_fdata()\n",
    "#load the truth data for subject 2\n",
    "s02_NDI_img = nib.load(s02_NDI_path)\n",
    "s02_ODI_img = nib.load(s02_ODI_path)\n",
    "s02_FWF_img = nib.load(s02_FWF_path)\n",
    "s02_NDI_affine = s02_NDI_img.affine\n",
    "s02_ODI_affine = s02_ODI_img.affine\n",
    "s02_FWF_affine = s02_FWF_img.affine\n",
    "s02_NDI_img_data = s02_NDI_img.get_fdata()\n",
    "s02_ODI_img_data = s02_ODI_img.get_fdata()\n",
    "s02_FWF_img_data = s02_FWF_img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "<h2>Random Rejection Scheme Setup</h2>\n",
    "Let N to be the tested number of retained volumes. For N, 100 subsampled schemes were drawn randomly from the full scheme (with the first b=0 volume and at least two different b values always included). Each subsampled schem was used to evaluate both techniques. For both 3D CNN and AMICO, N are 60, 40 and 30. We would give further undersampled scheme to 3D CNN, N are 20, 16 and 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list contains the N for each tested retained volume\n",
    "N = [60, 40, 30, 20, 16, 12]\n",
    "random_dict = {60:[], 40:[], 30:[], 20:[], 16:[], 12:[]}\n",
    "random_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated the random scheme for each tested volume\n",
    "for n in N:\n",
    "    # for each retained volume, we create 100 subsamples\n",
    "    for i in range(100):\n",
    "        ones = np.ones(n) # 1 = retained\n",
    "        zeros = np.zeros(96-n)\n",
    "\n",
    "        scheme = np.random.choice(np.concatenate([ones,zeros]), 96, replace=False)\n",
    "        scheme = ' '.join(map(str, scheme))\n",
    "        random_dict[n].append(scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rmse_dict = {60:[], 40:[], 30:[], 20:[], 16:[], 12:[]}\n",
    "cnn_ssim_dict = {60:[], 40:[], 30:[], 20:[], 16:[], 12:[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "<h2>Training</h2>\n",
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for the networks\n",
    "layers = 4 # the number of hidden layers; this is the optimal number of layer\n",
    "lr = 0.0001 # the learning rate\n",
    "patch_size = 3 # the size of patches for 2D and 3D CNN\n",
    "batch = 256 # the batch size\n",
    "epoch = 100 # the number of epoches for training\n",
    "\n",
    "# we firstly study subject s02, use s01 as a seperate training dataset\n",
    "study_subject = 's02_still' # the subject we want to study\n",
    "sep_train_subject = 's01_still' # this is separate training candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>N = 60</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for CNN\n",
    "for movefile in random_dict[60]:\n",
    "    # we have 100 movefiles for each retained tested volume\n",
    "    # Training\n",
    "    cnntrain_cmd = '--train_subjects ' + sep_train_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --lr ' + str(lr) + ' --batch ' + str(batch) + ' --patch_size ' + str(patch_size)\\\n",
    "               + ' --epoch ' + str(epoch) + ' --movefile ' + movefile + ' --train'\n",
    "    plot_loss(cnntrain_cmd)\n",
    "    # Testing\n",
    "    cnntest_cmd = '--test_subjects ' + study_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --movefile ' + movefile\n",
    "    cnntest_args = model_parser().parse_args(cnntest_cmd.split())\n",
    "    RMSE, SSIM = test_model(cnntest_args)\n",
    "    # Add results to the cnn dict\n",
    "    cnn_rmse_dict[60].append(RMSE)\n",
    "    cnn_ssim_dict[60].append(SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>N = 40</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for CNN\n",
    "for movefile in random_dict[40]:\n",
    "    # we have 100 movefiles for each retained tested volume\n",
    "    # Training\n",
    "    cnntrain_cmd = '--train_subjects ' + sep_train_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --lr ' + str(lr) + ' --batch ' + str(batch) + ' --patch_size ' + str(patch_size)\\\n",
    "               + ' --epoch ' + str(epoch) + ' --movefile ' + movefile + ' --train'\n",
    "    plot_loss(cnntrain_cmd)\n",
    "    # Testing\n",
    "    cnntest_cmd = '--test_subjects ' + study_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --movefile ' + movefile\n",
    "    cnntest_args = model_parser().parse_args(cnntest_cmd.split())\n",
    "    RMSE, SSIM = test_model(cnntest_args)\n",
    "    # Add results to the cnn dict\n",
    "    cnn_rmse_dict[40].append(RMSE)\n",
    "    cnn_ssim_dict[40].append(SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>N = 30</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for CNN\n",
    "for movefile in random_dict[30]:\n",
    "    # we have 100 movefiles for each retained tested volume\n",
    "    # Training\n",
    "    cnntrain_cmd = '--train_subjects ' + sep_train_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --lr ' + str(lr) + ' --batch ' + str(batch) + ' --patch_size ' + str(patch_size)\\\n",
    "               + ' --epoch ' + str(epoch) + ' --movefile ' + movefile + ' --train'\n",
    "    plot_loss(cnntrain_cmd)\n",
    "    # Testing\n",
    "    cnntest_cmd = '--test_subjects ' + study_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --movefile ' + movefile\n",
    "    cnntest_args = model_parser().parse_args(cnntest_cmd.split())\n",
    "    RMSE, SSIM = test_model(cnntest_args)\n",
    "    # Add results to the cnn dict\n",
    "    cnn_rmse_dict[30].append(RMSE)\n",
    "    cnn_ssim_dict[30].append(SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>N = 20</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for CNN\n",
    "for movefile in random_dict[20]:\n",
    "    # we have 100 movefiles for each retained tested volume\n",
    "    # Training\n",
    "    cnntrain_cmd = '--train_subjects ' + sep_train_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --lr ' + str(lr) + ' --batch ' + str(batch) + ' --patch_size ' + str(patch_size)\\\n",
    "               + ' --epoch ' + str(epoch) + ' --movefile ' + movefile + ' --train'\n",
    "    plot_loss(cnntrain_cmd)\n",
    "    # Testing\n",
    "    cnntest_cmd = '--test_subjects ' + study_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --movefile ' + movefile\n",
    "    cnntest_args = model_parser().parse_args(cnntest_cmd.split())\n",
    "    RMSE, SSIM = test_model(cnntest_args)\n",
    "    # Add results to the cnn dict\n",
    "    cnn_rmse_dict[20].append(RMSE)\n",
    "    cnn_ssim_dict[20].append(SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>N = 16</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for CNN\n",
    "for movefile in random_dict[16]:\n",
    "    # we have 100 movefiles for each retained tested volume\n",
    "    # Training\n",
    "    cnntrain_cmd = '--train_subjects ' + sep_train_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --lr ' + str(lr) + ' --batch ' + str(batch) + ' --patch_size ' + str(patch_size)\\\n",
    "               + ' --epoch ' + str(epoch) + ' --movefile ' + movefile + ' --train'\n",
    "    plot_loss(cnntrain_cmd)\n",
    "    # Testing\n",
    "    cnntest_cmd = '--test_subjects ' + study_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --movefile ' + movefile\n",
    "    cnntest_args = model_parser().parse_args(cnntest_cmd.split())\n",
    "    RMSE, SSIM = test_model(cnntest_args)\n",
    "    # Add results to the cnn dict\n",
    "    cnn_rmse_dict[16].append(RMSE)\n",
    "    cnn_ssim_dict[16].append(SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>N = 12</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for CNN\n",
    "for movefile in random_dict[12]:\n",
    "    # we have 100 movefiles for each retained tested volume\n",
    "    # Training\n",
    "    cnntrain_cmd = '--train_subjects ' + sep_train_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --lr ' + str(lr) + ' --batch ' + str(batch) + ' --patch_size ' + str(patch_size)\\\n",
    "               + ' --epoch ' + str(epoch) + ' --movefile ' + movefile + ' --train'\n",
    "    plot_loss(cnntrain_cmd)\n",
    "    # Testing\n",
    "    cnntest_cmd = '--test_subjects ' + study_subject + ' --model ' + model + ' --layer ' + str(layers) + ' --label_type ' + ltype + ' --movefile ' + movefile\n",
    "    cnntest_args = model_parser().parse_args(cnntest_cmd.split())\n",
    "    RMSE, SSIM = test_model(cnntest_args)\n",
    "    # Add results to the cnn dict\n",
    "    cnn_rmse_dict[12].append(RMSE)\n",
    "    cnn_ssim_dict[12].append(SSIM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d00557ecee9d041f78bfa618225def395bc332f64d1935e44218a847c69687c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
