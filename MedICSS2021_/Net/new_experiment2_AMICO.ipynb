{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>New Experiment 2: Random rejection of motion-free subjects</h1>\n",
    "In this notebook, random rejection tests were conducted using data from S1 in the still condition. The generalisation tests were conducted over S2. Each time we fix the number of retained volumes N. We randomly select N volumes from a subject's data, then we train our proposed model over this sample. At testing, we applied the same rejection scheme to S2, then test over the subset of S2.</br>\n",
    "We would like to show this proposed model is robust, by which it is independent of 1. The proportion of discarded volumes and 2. The different combinations of b-values.</br>\n",
    "<h2>Packages</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "packages that does conventional model fitting\n",
    "\"\"\"\n",
    "import amico\n",
    "\"\"\"\n",
    "packages that generate train/test dataset\n",
    "\"\"\"\n",
    "from FormatData import generate_data, parser as data_parser\n",
    "\"\"\"\n",
    "packages that produce the rejection shceme\n",
    "\"\"\"\n",
    "from filter_qa import parser as filter_parser, load_eddy\n",
    "\"\"\"\n",
    "package to store the intermediate result\n",
    "\"\"\"\n",
    "import pickle\n",
    "\"\"\"\n",
    "package to work out RMSE and SSIM\n",
    "\"\"\"\n",
    "from utils import calc_RMSE, calc_ssim, load_nii_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The class for parsing command line arguments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    \"\"\"\n",
    "    a class generate parser for cmd line args\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion-free subject path\n",
    "s01_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/'\n",
    "s02_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/'\n",
    "# motion-free target labels\n",
    "s01_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_NDI.nii'\n",
    "s02_NDI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_NDI.nii'\n",
    "\n",
    "s01_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_ODI.nii'\n",
    "s02_ODI_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_ODI.nii'\n",
    "\n",
    "s01_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/s01_still_FWF.nii'\n",
    "s02_FWF_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/s02_still_FWF.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask(subpath, fwfpath, threshold=0.99):\n",
    "    \"\"\"\n",
    "    By looking at the imgs generated, we have found out there are some regions that should not be included. Since they have values higher than 1.0\n",
    "    And we have found out voxels have NDI and ODI values, while that voxel has GROUND TRUTH FWF 1.0\n",
    "    This should indicate that that voxel should not even be included in the training\n",
    "    Therefore we want to filter the each subject's mask first, by using their corresponding GROUND TRUTH FWF\n",
    "\n",
    "    Args:\n",
    "        subpath (string): the path of the subject folder\n",
    "        fwfpath (string): the path of the corresponding fwf file\n",
    "        threshold (float): the thresholds to be used to filter of the mask,\n",
    "                           a stringnent threshold would be 0.9, the least stringnent threshold is 1.0\n",
    "                           by default, it is set to 0.99\n",
    "    \"\"\"\n",
    "    # fetch the mask data\n",
    "    img_mask = nib.load(subpath+'mask-e.nii')\n",
    "    original_mask = img_mask.get_fdata()\n",
    "    original_affine = img_mask.affine\n",
    "    shape = original_mask.shape # retain the shape of the mask\n",
    "    origin_nonzeros = np.count_nonzero(original_mask)\n",
    "    print('original mask has: ' + str(origin_nonzeros) + ' of nonzero voxels')\n",
    "    # fetch the FWF data\n",
    "    fwf = nib.load(fwfpath).get_fdata()\n",
    "    # filter\n",
    "    mask = original_mask.flatten() # this makes a copy of the orginal mask\n",
    "    fwf = fwf.reshape(mask.shape[0]) # reshape fwf to the corresponding shape\n",
    "    for i in range(len(mask)):\n",
    "        # if fwf has high value, means there is no tissue\n",
    "        # therefore, the voxel should be excluded\n",
    "        if fwf[i] >= threshold:\n",
    "            mask[i] = 0.0\n",
    "    # reshape mask back\n",
    "    mask = mask.reshape(shape)\n",
    "    filter_nonzeros = np.count_nonzero(mask)\n",
    "    print('filtered mask has: ' +str(filter_nonzeros) + ' of nonzero voxels')\n",
    "    # save the mask\n",
    "    filter_img = nib.Nifti1Image(mask, original_affine)\n",
    "    nib.save(filter_img, subpath+'filtered_mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above code to filter each subject's mask. Store as filtered_mask.nii in each subject folder\n",
    "filter_mask(s01_path, s01_FWF_path)\n",
    "filter_mask(s02_path, s02_FWF_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered mask path for each subject\n",
    "s01_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s01_still/filtered_mask.nii'\n",
    "s02_mask_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/filtered_mask.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s01_mask = load_nii_image(s01_mask_path)\n",
    "s02_mask = load_nii_image(s02_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate the base dataset for s01_still and s02_still for all NODDI parameters.\n",
    "\"\"\"\n",
    "cmd = \"--base --label_type A --subjects s01_still s02_still\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using nib to fetch the ground truth img\n",
    "\"\"\"\n",
    "#load the truth data for subject 1\n",
    "s01_NDI_img = nib.load(s01_NDI_path)\n",
    "s01_ODI_img = nib.load(s01_ODI_path)\n",
    "s01_FWF_img = nib.load(s01_FWF_path)\n",
    "s01_NDI_affine = s01_NDI_img.affine\n",
    "s01_ODI_affine = s01_ODI_img.affine\n",
    "s01_FWF_affine = s01_FWF_img.affine\n",
    "s01_NDI_img_data = s01_NDI_img.get_fdata()\n",
    "s01_ODI_img_data = s01_ODI_img.get_fdata()\n",
    "s01_FWF_img_data = s01_FWF_img.get_fdata()\n",
    "#load the truth data for subject 2\n",
    "s02_NDI_img = nib.load(s02_NDI_path)\n",
    "s02_ODI_img = nib.load(s02_ODI_path)\n",
    "s02_FWF_img = nib.load(s02_FWF_path)\n",
    "s02_NDI_affine = s02_NDI_img.affine\n",
    "s02_ODI_affine = s02_ODI_img.affine\n",
    "s02_FWF_affine = s02_FWF_img.affine\n",
    "s02_NDI_img_data = s02_NDI_img.get_fdata()\n",
    "s02_ODI_img_data = s02_ODI_img.get_fdata()\n",
    "s02_FWF_img_data = s02_FWF_img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "<h2>Random Rejection Scheme Setup</h2>\n",
    "Let N to be the tested number of retained volumes. For N, 100 subsampled schemes were drawn randomly from the full scheme (with the first b=0 volume and at least two different b values always included). Each subsampled schem was used to evaluate both techniques. For both 3D CNN and AMICO, N are 60, 40 and 30. We would give further undersampled scheme to 3D CNN, N are 20, 16 and 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list contains the N for each tested retained volume\n",
    "# N = [60, 40]\n",
    "# random_dict = {60:[], 40:[]}\n",
    "# random_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated the random scheme for each tested volume\n",
    "# for n in N:\n",
    "#     # for each retained volume, we create 100 subsamples\n",
    "#     for i in range(100):\n",
    "#         ones = np.ones(n) # 1 = retained\n",
    "#         zeros = np.zeros(96-n)\n",
    "\n",
    "#         scheme = np.random.choice(np.concatenate([ones,zeros]), 96, replace=False)\n",
    "#         scheme = ' '.join(map(str, scheme))\n",
    "#         random_dict[n].append(scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the rejection scheme\n",
    "# random_60_file = 'random_60.pickle'\n",
    "# random_40_file = 'random_40.pickle'\n",
    "\n",
    "# with open(random_60_file, 'wb') as handle:\n",
    "#     pickle.dump(random_dict[60], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open(random_40_file, 'wb') as handle:\n",
    "#     pickle.dump(random_dict[40], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the random rejection is already set, we can load it\n",
    "random_60 = []\n",
    "with (open('/home/vw/Desktop/IndividualProject/MedICSS2021_/Net/random_60.pickle', \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            random_60.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "random_60 = np.array(random_60[0])\n",
    "\n",
    "random_40 = []\n",
    "with (open('/home/vw/Desktop/IndividualProject/MedICSS2021_/Net/random_40.pickle', \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            random_40.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "random_40 = np.array(random_40[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amico_rmse_dict = {60:[], 40:[]}\n",
    "amico_ssim_dict = {60:[], 40:[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "<h2>Model fit AMICO</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(path, file, combine, savename):\n",
    "    with open(path+savename, 'w') as fout:\n",
    "        read_path = path+file\n",
    "        read_file = open(read_path, 'r')\n",
    "        lines = read_file.readlines()\n",
    "        for line in lines:\n",
    "            temp = line.split()\n",
    "            temp = [e for e, b in zip(temp, combine) if b == 1]\n",
    "            fout.write(' '.join(e for e in temp))\n",
    "            fout.write('\\n')\n",
    "    fout.close()\n",
    "\n",
    "def writediffusion(path, file, combine):\n",
    "    img = nib.load(path+file)\n",
    "    data = img.get_fdata()\n",
    "    data = data[..., combine==1]\n",
    "    img = nib.Nifti1Image(data, np.eye(4))\n",
    "    nib.save(img, path+'remained_diffusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "<h2>N=60</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(random_60)//2):\n",
    "\n",
    "    # read the movefile\n",
    "    movefile = random_60[i]\n",
    "    movefile = movefile.split()\n",
    "    combine = np.array([int(float(num)) for num in movefile])\n",
    "    \n",
    "    # create the remained bvals and bvecs for s02 by applying its corresponding rejection scheme\n",
    "    s02_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/'\n",
    "    # write the remained bvals\n",
    "    writefile(s02_path, 'bvals', combine, savename='remained_bvals')\n",
    "    # write the remained bvecs\n",
    "    writefile(s02_path, 'bvecs', combine, savename='remained_bvecs')\n",
    "    # create the remained diffusion data\n",
    "    writediffusion(s02_path, 'diffusion.nii', combine)\n",
    "\n",
    "    amico.setup()\n",
    "    # generate a scheme file from the bvals/bvecs files as follows, using the remained bvals and bvecs. Because data rejection is applied\n",
    "    amico.util.fsl2scheme(s02_path+'remained_bvals', s02_path+'remained_bvecs')\n",
    "    ae = amico.Evaluation(\"/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI\", \"s02_still\")\n",
    "    # load the data\n",
    "    ae.load_data(dwi_filename = \"remained_diffusion.nii\", scheme_filename = \"remained_bvals.scheme\", mask_filename = \"filtered_mask.nii\", b0_thr = 0)\n",
    "    # Set model for NODDI and generate the response functions for all the compartments:\n",
    "    ae.set_model(\"NODDI\")\n",
    "    ae.generate_kernels()\n",
    "    ae.load_kernels()\n",
    "    # model fit. It takes a little time depending on the number of voxels (but much much faster than the original NODDI).\n",
    "    ae.fit()\n",
    "    # Finally, save the results as NIfTI images:\n",
    "    # ICVF = NDI\n",
    "    # ISOVF = FWF\n",
    "    # OD = ODI\n",
    "    ae.save_results()\n",
    "\n",
    "    # analyse the result\n",
    "    icvf_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_ICVF.nii.gz'\n",
    "    isovf_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_ISOVF.nii.gz'\n",
    "    od_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_OD.nii.gz'\n",
    "\n",
    "    icvf_img = nib.load(icvf_path)\n",
    "    icvf = icvf_img.get_fdata()\n",
    "    isovf_img = nib.load(isovf_path)\n",
    "    isovf = isovf_img.get_fdata()\n",
    "    od_img = nib.load(od_path)\n",
    "    od = od_img.get_fdata()\n",
    "\n",
    "    # work out RMSE and SSIM\n",
    "    RMSE = []\n",
    "    ndi_rmse = calc_RMSE(icvf, s02_NDI_img_data, s02_mask)\n",
    "    odi_rmse = calc_RMSE(od, s02_ODI_img_data, s02_mask)\n",
    "    fwf_rmse = calc_RMSE(isovf, s02_FWF_img_data, s02_mask)\n",
    "    RMSE.append(ndi_rmse)\n",
    "    RMSE.append(odi_rmse)\n",
    "    RMSE.append(fwf_rmse)\n",
    "\n",
    "    SSIM = []\n",
    "    ndi_ssim = calc_ssim(icvf, s02_NDI_img_data)\n",
    "    odi_ssim = calc_ssim(od, s02_ODI_img_data)\n",
    "    fwf_ssim = calc_ssim(isovf, s02_FWF_img_data)\n",
    "    SSIM.append(ndi_ssim)\n",
    "    SSIM.append(odi_ssim)\n",
    "    SSIM.append(fwf_ssim)\n",
    "\n",
    "    amico_rmse_dict[60].append(RMSE)\n",
    "    amico_ssim_dict[60].append(SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ami_rmse_60_ndi_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[0] for item in amico_rmse_dict[60][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_rmse_60_odi_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[1] for item in amico_rmse_dict[60][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_rmse_60_fwf_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[2] for item in amico_rmse_dict[60][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('ami_ssim_60_ndi'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[0] for item in amico_ssim_dict[60][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_ssim_60_odi'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[1] for item in amico_ssim_dict[60][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_ssim_60_fwf'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[2] for item in amico_ssim_dict[60][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(random_60)//2, len(random_60)):\n",
    "\n",
    "    # read the movefile\n",
    "    movefile = random_60[i]\n",
    "    movefile = movefile.split()\n",
    "    combine = np.array([int(float(num)) for num in movefile])\n",
    "    \n",
    "    # create the remained bvals and bvecs for s02 by applying its corresponding rejection scheme\n",
    "    s02_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/'\n",
    "    # write the remained bvals\n",
    "    writefile(s02_path, 'bvals', combine, savename='remained_bvals')\n",
    "    # write the remained bvecs\n",
    "    writefile(s02_path, 'bvecs', combine, savename='remained_bvecs')\n",
    "    # create the remained diffusion data\n",
    "    writediffusion(s02_path, 'diffusion.nii', combine)\n",
    "\n",
    "    amico.setup()\n",
    "    # generate a scheme file from the bvals/bvecs files as follows, using the remained bvals and bvecs. Because data rejection is applied\n",
    "    amico.util.fsl2scheme(s02_path+'remained_bvals', s02_path+'remained_bvecs')\n",
    "    ae = amico.Evaluation(\"/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI\", \"s02_still\")\n",
    "    # load the data\n",
    "    ae.load_data(dwi_filename = \"remained_diffusion.nii\", scheme_filename = \"remained_bvals.scheme\", mask_filename = \"filtered_mask.nii\", b0_thr = 0)\n",
    "    # Set model for NODDI and generate the response functions for all the compartments:\n",
    "    ae.set_model(\"NODDI\")\n",
    "    ae.generate_kernels()\n",
    "    ae.load_kernels()\n",
    "    # model fit. It takes a little time depending on the number of voxels (but much much faster than the original NODDI).\n",
    "    ae.fit()\n",
    "    # Finally, save the results as NIfTI images:\n",
    "    # ICVF = NDI\n",
    "    # ISOVF = FWF\n",
    "    # OD = ODI\n",
    "    ae.save_results()\n",
    "\n",
    "    # analyse the result\n",
    "    icvf_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_ICVF.nii.gz'\n",
    "    isovf_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_ISOVF.nii.gz'\n",
    "    od_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_OD.nii.gz'\n",
    "\n",
    "    icvf_img = nib.load(icvf_path)\n",
    "    icvf = icvf_img.get_fdata()\n",
    "    isovf_img = nib.load(isovf_path)\n",
    "    isovf = isovf_img.get_fdata()\n",
    "    od_img = nib.load(od_path)\n",
    "    od = od_img.get_fdata()\n",
    "\n",
    "    # work out RMSE and SSIM\n",
    "    RMSE = []\n",
    "    ndi_rmse = calc_RMSE(icvf, s02_NDI_img_data, s02_mask)\n",
    "    odi_rmse = calc_RMSE(od, s02_ODI_img_data, s02_mask)\n",
    "    fwf_rmse = calc_RMSE(isovf, s02_FWF_img_data, s02_mask)\n",
    "    RMSE.append(ndi_rmse)\n",
    "    RMSE.append(odi_rmse)\n",
    "    RMSE.append(fwf_rmse)\n",
    "\n",
    "    SSIM = []\n",
    "    ndi_ssim = calc_ssim(icvf, s02_NDI_img_data)\n",
    "    odi_ssim = calc_ssim(od, s02_ODI_img_data)\n",
    "    fwf_ssim = calc_ssim(isovf, s02_FWF_img_data)\n",
    "    SSIM.append(ndi_ssim)\n",
    "    SSIM.append(odi_ssim)\n",
    "    SSIM.append(fwf_ssim)\n",
    "\n",
    "    amico_rmse_dict[60].append(RMSE)\n",
    "    amico_ssim_dict[60].append(SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ami_rmse_60_ndi_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[0] for item in amico_rmse_dict[60][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_rmse_60_odi_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[1] for item in amico_rmse_dict[60][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_rmse_60_fwf_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[2] for item in amico_rmse_dict[60][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('ami_ssim_60_ndi'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[0] for item in amico_ssim_dict[60][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_ssim_60_odi'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[1] for item in amico_ssim_dict[60][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_ssim_60_fwf'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[2] for item in amico_ssim_dict[60][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "<h2>N=40</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(random_40)//2):\n",
    "\n",
    "    # read the movefile\n",
    "    movefile = random_40[i]\n",
    "    movefile = movefile.split()\n",
    "    combine = np.array([int(float(num)) for num in movefile])\n",
    "\n",
    "    # for j in range(1, len(combine)):\n",
    "    #     if combine[j] == 1:\n",
    "    #         combine[j] = 0\n",
    "    \n",
    "    # # the first volume, b=0 is always selected\n",
    "    # combine[0] = 1\n",
    "    \n",
    "    # create the remained bvals and bvecs for s02 by applying its corresponding rejection scheme\n",
    "    s02_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/'\n",
    "    # write the remained bvals\n",
    "    writefile(s02_path, 'bvals', combine, savename='remained_bvals')\n",
    "    # write the remained bvecs\n",
    "    writefile(s02_path, 'bvecs', combine, savename='remained_bvecs')\n",
    "    # create the remained diffusion data\n",
    "    writediffusion(s02_path, 'diffusion.nii', combine)\n",
    "\n",
    "    amico.setup()\n",
    "    # generate a scheme file from the bvals/bvecs files as follows, using the remained bvals and bvecs. Because data rejection is applied\n",
    "    amico.util.fsl2scheme(s02_path+'remained_bvals', s02_path+'remained_bvecs')\n",
    "    ae = amico.Evaluation(\"/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI\", \"s02_still\")\n",
    "    # load the data\n",
    "    ae.load_data(dwi_filename = \"remained_diffusion.nii\", scheme_filename = \"remained_bvals.scheme\", mask_filename = \"filtered_mask.nii\", b0_thr = 0)\n",
    "    # Set model for NODDI and generate the response functions for all the compartments:\n",
    "    ae.set_model(\"NODDI\")\n",
    "    ae.generate_kernels()\n",
    "    ae.load_kernels()\n",
    "    # model fit. It takes a little time depending on the number of voxels (but much much faster than the original NODDI).\n",
    "    ae.fit()\n",
    "    # Finally, save the results as NIfTI images:\n",
    "    # ICVF = NDI\n",
    "    # ISOVF = FWF\n",
    "    # OD = ODI\n",
    "    ae.save_results()\n",
    "\n",
    "    # analyse the result\n",
    "    icvf_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_ICVF.nii.gz'\n",
    "    isovf_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_ISOVF.nii.gz'\n",
    "    od_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_OD.nii.gz'\n",
    "\n",
    "    icvf_img = nib.load(icvf_path)\n",
    "    icvf = icvf_img.get_fdata()\n",
    "    isovf_img = nib.load(isovf_path)\n",
    "    isovf = isovf_img.get_fdata()\n",
    "    od_img = nib.load(od_path)\n",
    "    od = od_img.get_fdata()\n",
    "\n",
    "    # work out RMSE and SSIM\n",
    "    RMSE = []\n",
    "    ndi_rmse = calc_RMSE(icvf, s02_NDI_img_data, s02_mask)\n",
    "    odi_rmse = calc_RMSE(od, s02_ODI_img_data, s02_mask)\n",
    "    fwf_rmse = calc_RMSE(isovf, s02_FWF_img_data, s02_mask)\n",
    "    RMSE.append(ndi_rmse)\n",
    "    RMSE.append(odi_rmse)\n",
    "    RMSE.append(fwf_rmse)\n",
    "\n",
    "    SSIM = []\n",
    "    ndi_ssim = calc_ssim(icvf, s02_NDI_img_data)\n",
    "    odi_ssim = calc_ssim(od, s02_ODI_img_data)\n",
    "    fwf_ssim = calc_ssim(isovf, s02_FWF_img_data)\n",
    "    SSIM.append(ndi_ssim)\n",
    "    SSIM.append(odi_ssim)\n",
    "    SSIM.append(fwf_ssim)\n",
    "\n",
    "    amico_rmse_dict[60].append(RMSE)\n",
    "    amico_ssim_dict[60].append(SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ami_rmse_40_ndi_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[0] for item in amico_rmse_dict[40][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_rmse_40_odi_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[1] for item in amico_rmse_dict[40][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_rmse_40_fwf_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[2] for item in amico_rmse_dict[40][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('ami_ssim_40_ndi'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[0] for item in amico_ssim_dict[40][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_ssim_40_odi'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[1] for item in amico_ssim_dict[40][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_ssim_40_fwf'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[2] for item in amico_ssim_dict[40][:50]], file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(random_40)//2, len(random_40)):\n",
    "\n",
    "    # read the movefile\n",
    "    movefile = random_40[i]\n",
    "    movefile = movefile.split()\n",
    "    combine = np.array([int(float(num)) for num in movefile])\n",
    "    \n",
    "    # create the remained bvals and bvecs for s02 by applying its corresponding rejection scheme\n",
    "    s02_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/'\n",
    "    # write the remained bvals\n",
    "    writefile(s02_path, 'bvals', combine, savename='remained_bvals')\n",
    "    # write the remained bvecs\n",
    "    writefile(s02_path, 'bvecs', combine, savename='remained_bvecs')\n",
    "    # create the remained diffusion data\n",
    "    writediffusion(s02_path, 'diffusion.nii', combine)\n",
    "\n",
    "    amico.setup()\n",
    "    # generate a scheme file from the bvals/bvecs files as follows, using the remained bvals and bvecs. Because data rejection is applied\n",
    "    amico.util.fsl2scheme(s02_path+'remained_bvals', s02_path+'remained_bvecs')\n",
    "    ae = amico.Evaluation(\"/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI\", \"s02_still\")\n",
    "    # load the data\n",
    "    ae.load_data(dwi_filename = \"remained_diffusion.nii\", scheme_filename = \"remained_bvals.scheme\", mask_filename = \"filtered_mask.nii\", b0_thr = 0)\n",
    "    # Set model for NODDI and generate the response functions for all the compartments:\n",
    "    ae.set_model(\"NODDI\")\n",
    "    ae.generate_kernels()\n",
    "    ae.load_kernels()\n",
    "    # model fit. It takes a little time depending on the number of voxels (but much much faster than the original NODDI).\n",
    "    ae.fit()\n",
    "    # Finally, save the results as NIfTI images:\n",
    "    # ICVF = NDI\n",
    "    # ISOVF = FWF\n",
    "    # OD = ODI\n",
    "    ae.save_results()\n",
    "\n",
    "    # analyse the result\n",
    "    icvf_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_ICVF.nii.gz'\n",
    "    isovf_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_ISOVF.nii.gz'\n",
    "    od_path = '/home/vw/Desktop/IndividualProject/MedICSS2021_/Data-NODDI/s02_still/AMICO/NODDI/FIT_OD.nii.gz'\n",
    "\n",
    "    icvf_img = nib.load(icvf_path)\n",
    "    icvf = icvf_img.get_fdata()\n",
    "    isovf_img = nib.load(isovf_path)\n",
    "    isovf = isovf_img.get_fdata()\n",
    "    od_img = nib.load(od_path)\n",
    "    od = od_img.get_fdata()\n",
    "\n",
    "    # work out RMSE and SSIM\n",
    "    RMSE = []\n",
    "    ndi_rmse = calc_RMSE(icvf, s02_NDI_img_data, s02_mask)\n",
    "    odi_rmse = calc_RMSE(od, s02_ODI_img_data, s02_mask)\n",
    "    fwf_rmse = calc_RMSE(isovf, s02_FWF_img_data, s02_mask)\n",
    "    RMSE.append(ndi_rmse)\n",
    "    RMSE.append(odi_rmse)\n",
    "    RMSE.append(fwf_rmse)\n",
    "\n",
    "    SSIM = []\n",
    "    ndi_ssim = calc_ssim(icvf, s02_NDI_img_data)\n",
    "    odi_ssim = calc_ssim(od, s02_ODI_img_data)\n",
    "    fwf_ssim = calc_ssim(isovf, s02_FWF_img_data)\n",
    "    SSIM.append(ndi_ssim)\n",
    "    SSIM.append(odi_ssim)\n",
    "    SSIM.append(fwf_ssim)\n",
    "\n",
    "    amico_rmse_dict[60].append(RMSE)\n",
    "    amico_ssim_dict[60].append(SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ami_rmse_40_ndi_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[0] for item in amico_rmse_dict[40][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_rmse_40_odi_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[1] for item in amico_rmse_dict[40][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_rmse_40_fwf_'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[2] for item in amico_rmse_dict[40][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('ami_ssim_40_ndi'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[0] for item in amico_ssim_dict[40][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_ssim_40_odi'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[1] for item in amico_ssim_dict[40][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ami_ssim_40_fwf'+str(i)+'.pickle', 'wb') as file:\n",
    "    pickle.dump([item[2] for item in amico_ssim_dict[40][50:]], file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d00557ecee9d041f78bfa618225def395bc332f64d1935e44218a847c69687c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
