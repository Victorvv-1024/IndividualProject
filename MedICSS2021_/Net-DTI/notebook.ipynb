{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b164b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that tests the number of voxels that are useful in a DWI.\n",
    "path = \"../Data-NODDI/s01_still/s01_still_NDI.nii\"\n",
    "ODI_img = nib.load(path)\n",
    "ODI_data = ODI_img.get_fdata()\n",
    "non_zero = 0\n",
    "zeros = 0\n",
    "for ele in ODI_data:\n",
    "    for el in ele:\n",
    "        for e in el:\n",
    "            if e != 0.0:\n",
    "                non_zero += 1\n",
    "            else:\n",
    "                zeros += 1\n",
    "print(non_zero)\n",
    "print(zeros)\n",
    "print(\"useful voxels ratio: \"+str(non_zero/(non_zero + zeros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages that helps to evaluate the model performace\n",
    "from utils import calc_RMSE, calc_psnr, calc_ssim\n",
    "def evaluate_model(pred, target, mask):\n",
    "    rmse = calc_RMSE(pred, target, mask)\n",
    "    psnr = calc_psnr(pred, target)\n",
    "    ssim = calc_ssim(pred, target)\n",
    "    return(rmse, psnr, ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    \"\"\"\n",
    "    a class generate parser for cmd line args\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3911b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "packages that generate train/test dataset\n",
    "\"\"\"\n",
    "from FormatData import generate_data, parser as data_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fe906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "packages that trains network\n",
    "\"\"\"\n",
    "from Training import train_network\n",
    "from utils.model import parser as model_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b971333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "packages that test network\n",
    "\"\"\"\n",
    "from Testing import test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e78ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "packages that plot graphs\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_loss(cmd):\n",
    "    \"\"\"\n",
    "    A function that used to plot the loss curve for the trained network.\n",
    "    Args:\n",
    "        cmd: String, the command line in the terminal\n",
    "    \"\"\"\n",
    "    args = model_parser().parse_args(cmd.split())\n",
    "    history = train_network(args)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def show_slices(slices):\n",
    "   \"\"\" Function to display row of image slices \"\"\"\n",
    "   fig, axes = plt.subplots(1, len(slices))\n",
    "   for i, slice in enumerate(slices):\n",
    "       axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a79258",
   "metadata": {},
   "source": [
    "<h3>Experiment 1. We want to discover the number of hidden acquired to produce promising each NODDI measure.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae9c93",
   "metadata": {},
   "source": [
    "<strong>Training subject: s01_still<br/>\n",
    "\n",
    "Test subject: s02_still<br/>\n",
    "\n",
    "Network; ANN<br/>\n",
    "\n",
    "Outcome: NDI<br/>\n",
    "\n",
    "\n",
    "The training data is stored in datasets/data/s01_still-96-first-1d.mat<br/>\n",
    "\n",
    "The training label is stored in datasets/label/s01_still-NDI-96-first-1d.mat<br/>\n",
    "\n",
    "The testing data is stored in datasets/data/s02_still-96-first.mat<br/>\n",
    "\n",
    "The testing label is stored in datasets/label/s02_still-NDI-96-first.mat</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6eacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset NDI for ANN.\n",
    "Using all of the DWI. 96. as training size.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still --nDWI 96 --fc1d_train --label_type N\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate testing dataset. \n",
    "The testing dataset does NOT need to be processed. \n",
    "The testing samples are DWI images of size (85,85,50,96).\n",
    "The testing samples can be used for ANY network in this experiment.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s02_still --nDWI 96 --label_type N --test\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3910f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using nib to fetch the  data, used for evaluation\n",
    "\"\"\"\n",
    "s02_NDI_path = '../Data-NODDI/s02_still/s02_still_NDI.nii'\n",
    "s02_mask_path = '../Net-DTI/datasets/mask/mask_s02_still.nii'\n",
    "s02_NDI_img = nib.load(s02_NDI_path)\n",
    "s02_NDI_img_data = s02_NDI_img.get_fdata()\n",
    "s02_mask_img = nib.load(s02_mask_path)\n",
    "s02_mask_img_data = s02_mask_img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1c5d3",
   "metadata": {},
   "source": [
    "<strong>Train ANNs with different number of layers.<br/>\n",
    "Herein, at most 6-hidden-layer ANNs are trained.<br/>\n",
    "Loss curve for each ANN is plotted.<br/>\n",
    "The test result is also generated -- evaluation method used is RMSE between pred and reference.<br/>\n",
    "The reference image and the genereated image are displayed side by side</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25594ae7",
   "metadata": {},
   "source": [
    "<strong>1 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 1 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 1 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f950c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-fc1d-1layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbde8e5",
   "metadata": {},
   "source": [
    "<strong>2 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f26c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 2 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc450474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 2 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-fc1d-2layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e7c2ff",
   "metadata": {},
   "source": [
    "<strong>3 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e70228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 3 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 3 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcd5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-fc1d-3layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82666a",
   "metadata": {},
   "source": [
    "<strong>4 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 4 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2157c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 4 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-fc1d-4layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31fea7",
   "metadata": {},
   "source": [
    "<strong>5 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 5 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e98bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 5 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282fe9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-fc1d-5layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2f37c",
   "metadata": {},
   "source": [
    "<strong>6 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 6 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7252df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 6 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c584a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-fc1d-6layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784c57d",
   "metadata": {},
   "source": [
    "<strong>Training subject: s01_still</br>\n",
    "Test subject: s02_still</br>\n",
    "Network; ANN</br>\n",
    "Outcome: ODI</br>\n",
    "\n",
    "The training data is stored in datasets/data/s01_still-96-first-1d.mat</br>\n",
    "The training label is stored in datasets/label/s01_still-ODI-96-first-1d.mat</br>\n",
    "The testing data is stored in datasets/data/s02_still-96-first.mat</br>\n",
    "The testing label is stored in datasets/label/s02_still-ODI-96-first.mat</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763aa0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset ODI for ANN.\n",
    "Using all of the DWI. 96. as training size.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still --nDWI 96 --fc1d_train --label_type O\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b22697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate testing dataset. \n",
    "The testing dataset does NOT need to be processed. \n",
    "The testing samples are DWI images of size (85,85,50,96).\n",
    "The testing samples can be used for ANY network in this experiment.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s02_still --nDWI 96 --label_type O --test\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using nib to fetch the  data, used for evaluation\n",
    "\"\"\"\n",
    "s02_ODI_path = '../Data-NODDI/s02_still/s02_still_ODI.nii'\n",
    "s02_mask_path = '../Net-DTI/datasets/mask/mask_s02_still.nii'\n",
    "s02_ODI_img = nib.load(s02_ODI_path)\n",
    "s02_ODI_img_data = s02_ODI_img.get_fdata()\n",
    "s02_mask_img = nib.load(s02_mask_path)\n",
    "s02_mask_img_data = s02_mask_img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11875f1",
   "metadata": {},
   "source": [
    "<strong>1 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 1 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 1 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-fc1d-1layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4146c5",
   "metadata": {},
   "source": [
    "<strong>2 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f82fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 2 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a641ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 2 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2384a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-fc1d-2layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8400d",
   "metadata": {},
   "source": [
    "<strong>3 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f82fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 3 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1678f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 3 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f895dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-fc1d-3layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb50e41",
   "metadata": {},
   "source": [
    "<strong>4 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 4 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da42391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 4 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f34d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-fc1d-4layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d0fde",
   "metadata": {},
   "source": [
    "<strong>5 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 5 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac90ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 5 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-fc1d-5layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adebe982",
   "metadata": {},
   "source": [
    "<strong>6 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a023a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 6 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 6 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8054eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-fc1d-6layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9647b08",
   "metadata": {},
   "source": [
    "<strong>Training subject: s01_still</br>\n",
    "Test subject: s02_still</br>\n",
    "Network; ANN</br>\n",
    "Outcome: FWF</br>\n",
    "\n",
    "The training data is stored in datasets/data/s01_still-96-first-1d.mat</br>\n",
    "The training label is stored in datasets/label/s01_still-FWF-96-first-1d.mat</br>\n",
    "The testing data is stored in datasets/data/s02_still-96-first.mat</br>\n",
    "THe testing label is stored in datasets/label/s02_still-FWF-96-first.mat</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset FWF for ANN.\n",
    "Using all of the DWI. 96. as training size.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still --nDWI 96 --fc1d_train --label_type F\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e12afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate testing dataset. \n",
    "The testing dataset does NOT need to be processed. \n",
    "The testing samples are DWI images of size (85,85,50,96).\n",
    "The testing samples can be used for ANY network in this experiment.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s02_still --nDWI 96 --label_type F --test\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba865b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using nib to fetch the  data, used for evaluation\n",
    "\"\"\"\n",
    "s02_FWF_path = '../Data-NODDI/s02_still/s02_still_FWF.nii'\n",
    "s02_mask_path = '../Net-DTI/datasets/mask/mask_s02_still.nii'\n",
    "s02_FWF_img = nib.load(s02_FWF_path)\n",
    "s02_FWF_img_data = s02_FWF_img.get_fdata()\n",
    "s02_mask_img = nib.load(s02_mask_path)\n",
    "s02_mask_img_data = s02_mask_img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12e8066",
   "metadata": {},
   "source": [
    "<strong>1 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 1 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 1 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49981941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-fc1d-1layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_FWF_img_data[26, :, :]\n",
    "ref_slice_1 = s02_FWF_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_FWF_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97167339",
   "metadata": {},
   "source": [
    "<strong>2 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 2 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 2 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528bcf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-fc1d-2layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_FWF_img_data[26, :, :]\n",
    "ref_slice_1 = s02_FWF_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_FWF_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890d158",
   "metadata": {},
   "source": [
    "<strong>3 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c76799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 3 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 3 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-fc1d-3layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_FWF_img_data[26, :, :]\n",
    "ref_slice_1 = s02_FWF_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_FWF_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b0ca14",
   "metadata": {},
   "source": [
    "<strong>4 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb565be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 4 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 4 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016334c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-fc1d-4layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "# evaluate the model# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-fc1d-3layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_FWF_img_data[26, :, :]\n",
    "ref_slice_1 = s02_FWF_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_FWF_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9025a2fb",
   "metadata": {},
   "source": [
    "<strong>5 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 5 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 5 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9135bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-fc1d-5layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_FWF_img_data[26, :, :]\n",
    "ref_slice_1 = s02_FWF_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_FWF_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51332804",
   "metadata": {},
   "source": [
    "<strong>6 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa582089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model fc1d --layer 6 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11459c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model fc1d --layer 6 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-fc1d-6layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_FWF_img_data[26, :, :]\n",
    "ref_slice_1 = s02_FWF_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_FWF_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dc79d",
   "metadata": {},
   "source": [
    "<strong>Training subject: s01_still<br/>\n",
    "\n",
    "Test subject: s02_still<br/>\n",
    "\n",
    "Network; 2D-CNN<br/>\n",
    "\n",
    "Outcome: NDI<br/>\n",
    "\n",
    "\n",
    "The training data is stored in datasets/data/s01_still-96-first-2d.mat<br/>\n",
    "\n",
    "The training label is stored in datasets/label/s01_still-NDI-96-first-2d.mat<br/>\n",
    "\n",
    "The testing data is stored in datasets/data/s02_still-96-first.mat<br/>\n",
    "\n",
    "The testing label is stored in datasets/label/s02_still-NDI-96-first.mat</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22474340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset NDI for 2D CNN.\n",
    "Using all of the DWI. 96. as training size.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still --nDWI 96 --conv2d_train --label_type N\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53e6c0",
   "metadata": {},
   "source": [
    "<strong>Train 2D CNNs with different number of layers.<br/>\n",
    "Herein, at most 6-hidden-layer 2D CNNs are trained.<br/>\n",
    "Loss curve for each 2D CNN is plotted.<br/>\n",
    "The test result is also generated -- evaluation method used is RMSE between pred and reference.<br/>\n",
    "The reference image and the genereated image are displayed side by side</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0dec6",
   "metadata": {},
   "source": [
    "<strong>1 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e781a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 1 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf596a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 1 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3dc143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-conv2d-1layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3832b2",
   "metadata": {},
   "source": [
    "<strong>2 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 2 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 2 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-conv2d-2layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e36d3",
   "metadata": {},
   "source": [
    "<strong>3 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 3 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 3 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30982d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-conv2d-3layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f51d63d",
   "metadata": {},
   "source": [
    "<strong>4 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311399a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 4 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 4 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba61e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-conv2d-4layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eadb7d",
   "metadata": {},
   "source": [
    "<strong>5 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 5 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 5 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-conv2d-5layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1b4de",
   "metadata": {},
   "source": [
    "<strong>6 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 6 --train --label_type N\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28231f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 6 --label_type N\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-NDI-96-first-conv2d-6layer.nii'\n",
    "pred_NDI_img = nib.load(pred_path)\n",
    "pred_NDI_img_data = pred_NDI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_NDI_img_data, s02_NDI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_NDI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_NDI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_NDI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_NDI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_NDI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_NDI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_NDI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd694f",
   "metadata": {},
   "source": [
    "<strong>Training subject: s01_still<br/>\n",
    "\n",
    "Test subject: s02_still<br/>\n",
    "\n",
    "Network; 2D-CNN<br/>\n",
    "\n",
    "Outcome: ODI<br/>\n",
    "\n",
    "\n",
    "The training data is stored in datasets/data/s01_still-96-first-2d.mat<br/>\n",
    "\n",
    "The training label is stored in datasets/label/s01_still-ODI-96-first-2d.mat<br/>\n",
    "\n",
    "The testing data is stored in datasets/data/s02_still-96-first.mat<br/>\n",
    "\n",
    "The testing label is stored in datasets/label/s02_still-ODI-96-first.mat</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset NDI for 2D CNN.\n",
    "Using all of the DWI. 96. as training size.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still --nDWI 96 --conv2d_train --label_type O\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8373dc",
   "metadata": {},
   "source": [
    "<strong>1 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ea77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 1 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5eae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 1 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-conv2d-1layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80b682",
   "metadata": {},
   "source": [
    "<strong>2 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 2 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e35a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 2 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-conv2d-2layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9e3f8",
   "metadata": {},
   "source": [
    "<strong>3 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054810a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 3 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 3 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b045cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-conv2d-3layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0a32c",
   "metadata": {},
   "source": [
    "<strong>4 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 4 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4509a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 4 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15dcc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-conv2d-4layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca7003",
   "metadata": {},
   "source": [
    "<strong>5 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 5 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 5 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86463094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-conv2d-5layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ab56f",
   "metadata": {},
   "source": [
    "<strong>6 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1118be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 6 --train --label_type O\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10092c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 6 --label_type O\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4436a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-ODI-96-first-conv2d-6layer.nii'\n",
    "pred_ODI_img = nib.load(pred_path)\n",
    "pred_ODI_img_data = pred_ODI_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_ODI_img_data, s02_ODI_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI reference image\")\n",
    "\n",
    "pred_slice_0 = pred_ODI_img_data[26, :, :]\n",
    "pred_slice_1 = pred_ODI_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_ODI_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_ODI predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a60775",
   "metadata": {},
   "source": [
    "<strong>Training subject: s01_still<br/>\n",
    "\n",
    "Test subject: s02_still<br/>\n",
    "\n",
    "Network; 2D-CNN<br/>\n",
    "\n",
    "Outcome: FWF<br/>\n",
    "\n",
    "\n",
    "The training data is stored in datasets/data/s01_still-96-first-2d.mat<br/>\n",
    "\n",
    "The training label is stored in datasets/label/s01_still-FWF-96-first-2d.mat<br/>\n",
    "\n",
    "The testing data is stored in datasets/data/s02_still-96-first.mat<br/>\n",
    "\n",
    "The testing label is stored in datasets/label/s02_still-FWF-96-first.mat</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d28c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate training dataset FWF for 2D CNN.\n",
    "Using all of the DWI. 96. as training size.\n",
    "\"\"\"\n",
    "cmd = \"--subjects s01_still --nDWI 96 --conv2d_train --label_type F\"\n",
    "args = data_parser().parse_args(cmd.split())\n",
    "generate_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3dce38",
   "metadata": {},
   "source": [
    "<strong>1 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 1 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 1 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21af426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-conv2d-1layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FwF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ab23b",
   "metadata": {},
   "source": [
    "<strong>2 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7603f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 2 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ff732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 2 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-conv2d-2layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FwF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da7d90",
   "metadata": {},
   "source": [
    "<strong>3 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 3 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80fe83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 3 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08526b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-conv2d-3layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FwF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e70bb",
   "metadata": {},
   "source": [
    "<strong>4 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa506e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 4 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 4 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1793b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-conv2d-4layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FwF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136b442",
   "metadata": {},
   "source": [
    "<strong>5 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232eaf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 5 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 5 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-conv2d-5layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FwF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d1929",
   "metadata": {},
   "source": [
    "<strong>6 layer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41337e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer training\n",
    "cmd = \"--train_subjects s01_still --DWI 96 --model conv2d --layer 6 --train --label_type F\"\n",
    "plot_loss(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 layer testing\n",
    "cmd = \"--test_subjects s02_still --DWI 96 --model conv2d --layer 6 --label_type F\"\n",
    "args = model_parser().parse_args(cmd.split())\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference img and pred img\n",
    "pred_path = '../Net-DTI/nii/s02_still-FWF-96-first-conv2d-6layer.nii'\n",
    "pred_FWF_img = nib.load(pred_path)\n",
    "pred_FWF_img_data = pred_FWF_img.get_fdata()\n",
    "\n",
    "# evaluate the model\n",
    "eval_re = evaluate_model(pred_FWF_img_data, s02_FWF_img_data, s02_mask_img_data)\n",
    "print(eval_re)\n",
    "\n",
    "# visualise both ref img and pred img\n",
    "ref_slice_0 = s02_ODI_img_data[26, :, :]\n",
    "ref_slice_1 = s02_ODI_img_data[:, 30, :]\n",
    "ref_slice_2 = s02_ODI_img_data[:, :, 16]\n",
    "show_slices([ref_slice_0, ref_slice_1, ref_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FwF reference image\")\n",
    "\n",
    "pred_slice_0 = pred_FWF_img_data[26, :, :]\n",
    "pred_slice_1 = pred_FWF_img_data[:, 30, :]\n",
    "pred_slice_2 = pred_FWF_img_data[:, :, 16]\n",
    "show_slices([pred_slice_0, pred_slice_1, pred_slice_2])\n",
    "plt.suptitle(\"Center slices for s02_still_FWF predicted image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
